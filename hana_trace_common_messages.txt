||<val>[thr=<thread_id>]: <thread_type> at exception throw location: <level>: 0x<address> in <module>(<arguments>) at <library>:<line> (<shared_library>)||2313619|Lines following this pattern belong to call stacks that contain the coding location and call hierarchy in case of error situations.|exception throw location||
||Allocation failed|T0300|1999997|These low level errors indicate an out-of-memory (OOM) situation and can pop up in various components and contexts.|Allocation failed||
||Cannot allocate memory|T0300|1999997|These low level errors indicate an out-of-memory (OOM) situation and can pop up in various components and contexts.|||
||failed to allocate|T0300|1999997|These low level errors indicate an out-of-memory (OOM) situation and can pop up in various components and contexts.|||
||$failure_type$=CANCEL_FLAG||2092196|This error indicates that a session cancel request was performed by memory management. This feature is available starting with SAP HANA 2.0 SPS 04 in order to increase the probability to react to cancellations in time.|CANCEL_FLAG|failure_type|
||Attribute engine index not found|T0400|2116157|These errors indicates a corruption and can pop up invarious components and contexts.|Attribute engine index not found||
||Invalid checksum algorithm|T0402|2116157|These errors indicates a corruption and can pop up invarious components and contexts.|Invalid checksum algorithm||
||Invalid page type|T0404|2116157|These errors indicates a corruption and can pop up invarious components and contexts.|Invalid page type||
||Invalid savepoint version|T0406|2116157|These errors indicates a corruption and can pop up invarious components and contexts.|Invalid savepoint version||
||Invalid size class|T0408|2116157|These errors indicates a corruption and can pop up invarious components and contexts.|Invalid size class||
||Savepoint version must be newer|T0410|2116157|These errors indicates a corruption and can pop up invarious components and contexts.|Savepoint version must be newer||
||Savepoint version must be older|T0411|2116157|These errors indicates a corruption and can pop up invarious components and contexts.|Savepoint version must be older||
||Wrong checksum|T0412|2116157|These errors indicates a corruption and can pop up invarious components and contexts.|Wrong checksum||
||Wrong converter type|T0414|2116157|These errors indicates a corruption and can pop up invarious components and contexts.|Wrong converter type||
||Wrong next page number|T0416|2116157|These errors indicates a corruption and can pop up invarious components and contexts.|Wrong next page number||
||Wrong owner|T0418|2116157|These errors indicates a corruption and can pop up invarious components and contexts.|Wrong owner||
||Wrong page number|T0420|2116157|These errors indicates a corruption and can pop up invarious components and contexts.|Wrong page number||
||Wrong size class|T0422|2116157|These errors indicates a corruption and can pop up invarious components and contexts.|Wrong size class||
||Wrong savepoint version|T0424|2116157|These errors indicates a corruption and can pop up invarious components and contexts.|Wrong savepoint version||
||A communication error occurred, with the HDB TcpIp Server|T0500|2222200|Network or communication related problem|A communication error occurred|with the HDB TcpIp Server|
||an error occured while reading from the channel|T0501|2222200|Network or communication related problem|an error occured while reading from the channel||
||a timeout occured while reading from the channel|T0502|2222200|Network or communication related problem|a timeout occured while reading from the channel||
||Bad file descriptor|T0504|2222200|Network or communication related problem|Bad file descriptor||
||broken pipe|T0506|2222200|Network or communication related problem|broken pipe||
||Cannot assign requested address|T0507|2222200|Network or communication related problem|Cannot assign requested address||
||close channel while sending reply message|T0508|2222200|Network or communication related problem|close channel while sending reply message||
||connection broken|T0512|2222200|Network or communication related problem|connection broken||
||Connection from <source> over socket <socket> handled message of type|T0514|2222200|Network or communication related problem|Connection from|over socket|handled message of type
||connection refused|T0516|2222200|Network or communication related problem|connection refused||
||connection reset by peer|T0518|2222200|Network or communication related problem|connection reset by peer||
||connection timed out|T0520|2222200|Network or communication related problem|connection timed out||
||executor: communication problem|T0522|2222200|Network or communication related problem|executor|communication problem|
||Failed to send cancel request|T0524|2222200|Network or communication related problem|Failed to send cancel request||
||failed with NetException|T0526|2222200|Network or communication related problem|failed with NetException||
||NetworkChannel::connectBlocking refused|T0528|2222200|Network or communication related problem|NetworkChannel|connectBlocking refused|
||New connection accepted from <source>|T0530|2222200|Network or communication related problem|New connection accepted from||
||no connection could be made because the target machine actively refused it|T0532|2222200|Network or communication related problem|no connection could be made because the target machine actively refused it||
||no reachable host left|T0534|2222200|Network or communication related problem|no reachable host left||
||no route to host|T0536|2222200|Network or communication related problem|no route to host||
||read from channel failed|T0538|2222200|Network or communication related problem|read from channel failed||
||reading failed with timeout error|T0540|2222200|Network or communication related problem|reading failed with timeout error||
||resetting buffer (timeout occured)|T0542|2222200|Network or communication related problem|resetting buffer|timeout occured|
||stream: send error|T0544|2222200|Network or communication related problem|stream|send error|
||temporary failure in name resolution|T0546|2222200|Network or communication related problem|temporary failure in name resolution||
||unexpected error with unknown peer name|T0548|2222200|Network or communication related problem|unexpected error with unknown peer name||
||Unexpected stream close|T0550|2222200|Network or communication related problem|Unexpected stream close||
||unknown host|T0552|2222200|Network or communication related problem|unknown host||
||pingNameServer takes <seconds> seconds. Communication problem or interval <interval> too short?|T0845|2222110|Check why the nameserver ping takes longer than expected.|pingNameServer takes|Communication problem or interval|too short
||Authorization error|T0916|2159014|Authorization / permission problems|Authorization error||
||insufficient privilege|T0915|2433916|Authorization / permission problems|insufficient privilege||
||cannot establish session because the initial communication timeout was reached|T0554|2385992|Connection timeout|cannot establish session because the initial communication timeout was reached||
||Maximum number of rows per partition reached|T2020|2154870|This message indicates that a table / partition has reached the 2 billion record limit. Either reduce the data volume or consider setting up (more) partitions (SAP Note 2044468).|Maximum number of rows per partition reached||
||Olap temporary data size exceeded 31/32 bit limit|T2002|2154870|This error indicates that an intermediate data set exceeded the 2 billion / 4 billion record limit. If it happens during index creation on a large partitioned table the problem can be bypassed by temporarily setting the following SAP HANA parameter: indexserver.ini -> [query_mediator] -> local_group_bys_max_table_sets_per_host = 0. In other cases you need to optimize the underlying database request so that the amount of processed data is reduced (SAP Note 2000002).|Olap temporary data size exceeded||
||No space left on device|T0600|1999930|This low level error indicates a file system overflow and can pop up in various components and contexts. This error can also pop up in context of shared memory, see check ID T0319 for details.|No space left on device||
||reading failed with timeout error; timeout=<timeout>ms elapsed||2222200|Communication read timeout|reading failed with timeout error|timeout|elapsed
||temp index not exists|T0244||This error indicates that a temp index can t be found (e.g. during procedure execution).|temp index not exists||
||transaction rolled back by lock wait timeout|T0700|1999998|Termination of transactional lock wait taking longer than the time defined with parameter indexserver.ini -> [transaction] -> lock_wait_timeout. ATTENTION: This error may be erroneously reported in context of other lock related errors (e.g. "failed to acquire record lock. Too many waiting transactions"), so in case of doubts you should check the related entries in the trace file in detail.|transaction rolled back by lock wait timeout||
||[2625] execution plan aborted||2092196|Cancellation of current operation (e.g. by end user, timeout or MVCC anti ager) and rollback|2625|execution plan aborted|
||(OlapEngine/Parallel/CompactResultColumn.cpp:923)||2092196|Cancellation of current operation (e.g. by end user, timeout or MVCC anti ager) and rollback|OlapEngine|Parallel|CompactResultColumn.cpp
||current operation canceled by request||2092196|Cancellation of current operation (e.g. by end user, timeout or MVCC anti ager) and rollback|current operation canceled by request||
||current operation cancelled by request||2092196|Cancellation of current operation (e.g. by end user, timeout or MVCC anti ager) and rollback|current operation cancelled by request||
||exception 2625||2092196|Cancellation of current operation (e.g. by end user, timeout or MVCC anti ager) and rollback|exception 2625||
||exception 6892||2092196|Cancellation of current operation (e.g. by end user, timeout or MVCC anti ager) and rollback|exception 6892||
||exception %70002625||2092196|Cancellation of current operation (e.g. by end user, timeout or MVCC anti ager) and rollback|exception %70002625||
||exception %70006892||2092196|Cancellation of current operation (e.g. by end user, timeout or MVCC anti ager) and rollback|exception %70006892||
||no.2040026||2092196|Cancellation of current operation (e.g. by end user, timeout or MVCC anti ager) and rollback|no.2040026||
||Operation cancelled||2092196|Cancellation of current operation (e.g. by end user, timeout or MVCC anti ager) and rollback|Operation cancelled||
||plan aborted(23051)||2092196|Cancellation of current operation (e.g. by end user, timeout or MVCC anti ager) and rollback|plan aborted|23051|
||rc=2040026||2092196|Cancellation of current operation (e.g. by end user, timeout or MVCC anti ager) and rollback|rc=2040026||
||rc = 2625||2092196|Cancellation of current operation (e.g. by end user, timeout or MVCC anti ager) and rollback|rc = 2625||
||rc 23051||2092196|Cancellation of current operation (e.g. by end user, timeout or MVCC anti ager) and rollback|rc 23051||
||string is too long exception||2457876|This error can happen with SAP HANA >= 1.0 SPS 12 if an input parameter value is too long. The length check can be suppressed with the following parameter setting: indexserver.ini -> [sqlscript] -> typecheck_procedure_input_param = false|string is too long exception||
adapter_framework|operationCacheContainer.cpp|Unable to instantiate transform of type <type> because of error: exception 141005: Failed to create or initialize HanaTransform object|T2200|2635266 2713209|This error is typically a consequence of missing Geocoder directory data or an invalid reference path configured. Check and adjust the setting of: scriptserver.ini -> [adapter_framework] -> dq_reference_data_path|Unable to instantiate transform of type|exception 141005|Failed to create or initialize HanaTransform object
AMD|deployCalcView.cpp|Create Scenario: failed, printing XML <xml>|||This is a general error message including XML scenario information in case there was a problem creating a calculation scenario, detailed errors can be found in related trace file entries, e.g. "Inconsistent calculation model".|Create Scenario|failed|printing XML
assign|TREXIndexServer.cpp|assign failed with ltt exception. stopping service... : exception 1: no.10000062 (ims_search_api/Delta/CheckForOldDeltaLogEntries.cpp:301) Delta log migration failed, for further details please refer to the trace files and to SAP Note 2372809||2372809|This error results in a termination of a service startup due to an outdated delta log format.|assign failed with ltt exception|stopping service|Delta log migration failed
attributes|AttributeStore.cpp|bad alloc in avc->open()||1999997|This error typically indicates an out of memory scenario when loading a column in column store.|bad alloc in avc|open|
attributes|AttributeStoreFile.h|AttributeStoreFile error I <schema> <table> A A attribute_<id>.bin: AttributeEngine: error reading file; failed with rc 6946||2116157|This error indicates a corruption|AttributeStoreFile error|error reading file|failed with rc 6946
attributes|AttributeEngine.cpp AttributeValueContainer.cpp|load failed|T0800|2127458|Failure during column load|load failed||
attributes|OpenAttributeHelper.cpp|failed to open attribute <col_id> of index <sid>::<schema>:#_SYS_QO_COL_<id> (t <id>), error = <error>|T0202|2588119|This error indicates a problem loading a column. Underlying issues depend on the reported <error>, e.g.: 6915: This error happens in context of a bug with SAP HANA 2.0 <= Rev. 2.00.023 when the Extended SQL Executor (ESX) is used. 6952: Out of memory while loading the column (SAP Note 1999997)|failed to open attribute|_SYS_QO_COL_|
attributes|ValueDictPredicate.cpp|<sid>::<schema>::<table>.<column> QUERY_OP_BT <<num> values> 6934: not enough or too many operands for attribute search operator|T0204|2276838 2399993|This error indicates a mismatch of operands for the attribute search and is typically caused by a problem on application side. It can also be caused by a SAP HANA bug in context of FDA (SAP Note 2399993) and partitioned tables that is fixed with SAP HANA >= 2.00.012.04 and >= 2.00.024.|QUERY_OP_BT|6934|not enough or too many operands for attribute search operator
Authentication|AbstractMethodGSSAcceptor.cpp|Error during Kerberos: ... Clock skew too great|T0930|1283986|This message indicates that authentication was rejected due to a significant system time difference between SAP HANA client and server.|Error during Kerberos|Clock skew too great|
Authentication|SAPLogonManager.cpp|Error while reading from SAP Logon TrustStore|T0900|2311047|Unsuccessful access to SAP logon truststore|Error while reading from SAP Logon TrustStore||
Authorization|CatalogAuthorizationStorageManager.cpp|Unknown DML restriction state detected: <id> for object: ObjectId(<id>, <id>,oid=<oid>) and privilege: <priv_id>|T0905||These warnings are harmless and can be ignored. Starting with SAP HANA 1.00.122.14 they will no longer be printed to the database trace files.|Unknown DML restriction state detected|ObjectId|privilege
Authorization|EAPIUtils.cc|EAPI::hasClientParameterAdminPrivilege - user[<user>] does not have client parameter admin privilege||2159014 2657901|This trace file entry is linked to an activated authorization trace and indicates a missing privilege.|EAPI|hasClientParameterAdminPrivilege|does not have client parameter admin privilege
Authorization|SQLFacade.cpp|User <user> is missing privilege <privilege>|T0914|2159014 2657901|This trace file entry is linked to an activated authorization trace and indicates a missing privilege.|User|is missing privilege|
Authorization|SqlAnalyticalPrivilegeFacade.cpp|Failed to obtain analytical privilege definition: <definition> due to error: Invalid SQL AP definition|T0910|2462871|Unsupported combination of SQL analytic privilege and repository procedure|Failed to obtain analytical privilege definition:|due to error|Invalid SQL AP definition
Authorization|qo_rewrite_rules.cc|Could not obtain all relevant analytical privileges for user <user> accessing view <view> due to exception: Invalid SQL AP definition||2462871|Unsupported combination of SQL analytic privilege and repository procedure|Could not obtain all relevant analytical privileges for user|due to exception|Invalid SQL AP definition
Backup|BackupDestBackint_Executor.cpp|BackupDestBackint_Executor: Backint did not respond for <seconds> seconds, killing pid <pid>|T1000|2472144|Backint response timeout|BackupDestBackint_Executor|Backint did not respond for|killing pid
Backup|BackupExe_LogBackup.cpp|Report backup failure: Object <id> with the value <id> does not exist||2601881|This error can be a consequence of inadequate error handling when after a log backup was terminated. Restarting the related service can resolve the issue.|Report backup failure|with the value|does not exist
Backup|BackupExe_LogBackupInformation.cpp|Exception caught while trying to close destination: exception 1: no.110089 ... Error writing backup to BACKINT|T1005|2222200|Problem writing backup, e.g. communication issue, see related errors for details|Exception caught while trying to close destination|Error writing backup to|BACKINT
Backup|BackupMgr_DeltaBackupTracker.cpp|[DBT] received BackupCatalog_DataBackupFinishEntry for <id>||1642148|Data backup status information|DBT|received BackupCatalog_DataBackupFinishEntry for|
Backup|BackupMgr_DeltaBackupTracker.cpp|[DBT] received BackupCatalog_DataBackupFinishEntry for <id>||1642148|Data backup status information|DBT|received BackupCatalog_DataBackupStartEntry for|
Backup|BackupMgr_DeltaBackupTracker.cpp|[DBT] received BackupCatalog_DataBackupFinishEntry for <id>||1642148|Data backup status information|DBT|received BackupCatalog_DataDestinationFinishEntry for|
Backup|BackupMgr_DeltaBackupTracker.cpp|[DBT] received BackupCatalog_DataBackupFinishEntry for <id>||1642148|Data backup status information|DBT|received BackupCatalog_DataDestinationStartEntry for|
Backup|BackupMgr_DeltaBackupTracker.cpp|[DBT] received BackupCatalog_DataBackupFinishEntry for <id>||1642148|Data backup status information|DBT|received BackupCatalog_DifferentialBackupFinishEntry for|
Backup|BackupMgr_DeltaBackupTracker.cpp|[DBT] received BackupCatalog_DataBackupFinishEntry for <id>||1642148|Data backup status information|DBT|received BackupCatalog_DifferentialBackupStartEntry for|
Backup|BackupMgr_DeltaBackupTracker.cpp|Backup <id> is not usable because of takeover on standby||1642148|This information message indicates that a specific backup can not be used because a takeover has taken place.|Backup|is not usable because of takeover on standby|
Backup|BackupMgr_Manager.cpp|SAVE DATA started||1642148|Start of data backup|SAVE DATA started||
Backup|BackupMgr_Manager.cpp|SAVE DATA finished with error: [447] backup could not be completed, [2000004] Cannot open file "<file>", ... rc=13: Permission denied|T1008|1642148 1999930|Unsuccessful termination of data backup|SAVE DATA finished with error|Cannot open file|Permission denied
Backup|BackupMgr_Manager.cpp|SAVE DATA finished with error: [447] backup could not be completed, [110512] Backint reported BACKINT backup job into <target> failed with error code ERROR in file <file>|T1008|1642148 1999930|Unsuccessful termination of data backup|SAVE DATA finished with error|BACKINT backup job into|failed with error code ERROR
Backup|BackupMgr_SaveDataJob.cpp|SAVE DATA finished successfully||1642148|Successful completion of data backups|SAVE DATA finished successfully||
Backup|BackupStrategy_Catalog.cpp|BackupStrategy_Catalog::addEntry: DataBackupDeleteEntry without matching start entry, ignored||1642148|These messages are printed when the backup catalog is parsed in order to determine a backup strategy. This typically happens when the first backup after startup or takeover is performed. Reasons for these "inconsistencies" can be failed backups or CLEAR LOG operations. Normally there is no need to worry about it. You can use hdbbackupdiag in order to check the recoverability of the database (SAP Note 1873247). You can clear older inconsistencies by performing backup catalog housekeeping (SAP Note 2400024).|BackupStrategy_Catalog|DataBackupDeleteEntry without matching start entry|ignored
Backup|BackupStrategy_Catalog.cpp|BackupStrategy_Catalog::addEntry: DataBackupDeleteEntry without matching start entry, ignored||1642148|These messages are printed when the backup catalog is parsed in order to determine a backup strategy. This typically happens when the first backup after startup or takeover is performed. Reasons for these "inconsistencies" can be failed backups or CLEAR LOG operations. Normally there is no need to worry about it. You can use hdbbackupdiag in order to check the recoverability of the database (SAP Note 1873247). You can clear older inconsistencies by performing backup catalog housekeeping (SAP Note 2400024).|Deleting|unfinished entries for volume|
Backup|BackupStrategy_Catalog.cpp|BackupStrategy_Catalog::addEntry: DataBackupDeleteEntry without matching start entry, ignored||1642148|These messages are printed when the backup catalog is parsed in order to determine a backup strategy. This typically happens when the first backup after startup or takeover is performed. Reasons for these "inconsistencies" can be failed backups or CLEAR LOG operations. Normally there is no need to worry about it. You can use hdbbackupdiag in order to check the recoverability of the database (SAP Note 1873247). You can clear older inconsistencies by performing backup catalog housekeeping (SAP Note 2400024).|Deleting|unfinished entries from catalog|
Backup|BackupStrategy_Catalog.cpp|BackupStrategy_Catalog::addEntry: DataBackupDeleteEntry without matching start entry, ignored||1642148|These messages are printed when the backup catalog is parsed in order to determine a backup strategy. This typically happens when the first backup after startup or takeover is performed. Reasons for these "inconsistencies" can be failed backups or CLEAR LOG operations. Normally there is no need to worry about it. You can use hdbbackupdiag in order to check the recoverability of the database (SAP Note 1873247). You can clear older inconsistencies by performing backup catalog housekeeping (SAP Note 2400024).|Entry|already tracked|
Backup|BackupStrategy_Catalog.cpp|BackupStrategy_Catalog::addEntry: DataBackupDeleteEntry without matching start entry, ignored||1642148|These messages are printed when the backup catalog is parsed in order to determine a backup strategy. This typically happens when the first backup after startup or takeover is performed. Reasons for these "inconsistencies" can be failed backups or CLEAR LOG operations. Normally there is no need to worry about it. You can use hdbbackupdiag in order to check the recoverability of the database (SAP Note 1873247). You can clear older inconsistencies by performing backup catalog housekeeping (SAP Note 2400024).|Log backup did not fit to recovery entry||
Backup|BackupStrategy_Catalog.cpp|BackupStrategy_Catalog::addEntry: DataBackupDeleteEntry without matching start entry, ignored||1642148|These messages are printed when the backup catalog is parsed in order to determine a backup strategy. This typically happens when the first backup after startup or takeover is performed. Reasons for these "inconsistencies" can be failed backups or CLEAR LOG operations. Normally there is no need to worry about it. You can use hdbbackupdiag in order to check the recoverability of the database (SAP Note 1873247). You can clear older inconsistencies by performing backup catalog housekeeping (SAP Note 2400024).|Unable to untrack catalog entry|Entry not found|
Basis|ChannelListener.cpp|Application for this process will only work with hdbcons -p <pid>|T0805|1999880 2222218 2477204|These messages indicate that the same time of service (e.g. hdbnsutil, hdbindexserver) was running at least two times in parallel. Only the first service can be accessed via socket by hdbcons, the others need to be addressed explicitly via hdbcons option "-p <pid>". If these messages show up in context of hdbnsutil calls, it doesn't mean a real problem. Nevertheless it indicates that multiple hdbnsutil calls are executed at roughly the same time, so you should check if you can minimize the number of calls (e.g. by reducing the number of system replication state checks via "hdbnsutil -sr_state"). In case of other services like hdbindexserver it can be a normal effect of temporary or permanent system configurations with more than one service with the same service type being started on one SAP HANA node.|Application for this process will only work with|hdbcons|
Basis|ChannelListener.cpp|Unable to create socket for name: <service>_..._ExternalCommandHandle|T0805|1999880 2222218 2477204|These messages indicate that the same time of service (e.g. hdbnsutil, hdbindexserver) was running at least two times in parallel. Only the first service can be accessed via socket by hdbcons, the others need to be addressed explicitly via hdbcons option "-p <pid>". If these messages show up in context of hdbnsutil calls, it doesn t mean a real problem. Nevertheless it indicates that multiple hdbnsutil calls are executed at roughly the same time, so you should check if you can minimize the number of calls (e.g. by reducing the number of system replication state checks via "hdbnsutil -sr_state"). In case of other services like hdbindexserver it can be a normal effect of temporary or permanent system configurations with more than one service with the same service type being started on one SAP HANA node.|Unable to create socket for name|ExternalCommandHandle|
Basis|ELF.cpp|Using only dynamic symbol table for symbols of ELF file '<library_path_and_name>', no string section|T0810|2313619|This warning indicates that a library was "stripped", so it was loaded without debug symbols. As a consequence the SAP HANA call stack analysis can be more difficult because less granular dynamic symbols are used as a basis. In the worst case these dynamic symbols point to a wrong module. In general all SAP HANA modules should contain a proper symbol table, for external software this can't be guaranteed. In the following cases the warning can be ignored: ISYS libraries for converting binary formats (e.g. pdf, doc) in preprocessor into text or HTML (libISYS11df.so, libISYSreaders.so, libISYSshared.so). ODBC driver libraries (libdbicudt17.so, libdbtasks17_r.so, libdbicu17_r.so, libdbodm17.so). In SAP HANA Express environments libraries are stripped per default. If you receive this warning for modules that aren't mentioned in the above exception list, yet, you can open a SAP incident on component HAN-DB for clarification. See the blog SAP HANA gets stripped for a more detailed discussion about this topic.|Using only dynamic symbol table for symbols of ELF file|library_path_and_name|no string section
Basis|ExternalCommandHandler.cpp|Execute hdbcons command : <arguments>||2222218|Execution of hdbcons command|Execute hdbcons command||
Basis|FaultProtectionImpl.cpp|SIGNAL 6 (SIGABRT) caught|T0220|2177064|These messages indicate that a signal was sent to the SAP HANA database: Signal 6: abort and Signal 11: segmentation fault, leading to service crash|SIGNAL 6|SIGABRT|caught
Basis|FaultProtectionImpl.cpp|SIGNAL 6 (SIGABRT) caught|T0220|2177064|These messages indicate that a signal was sent to the SAP HANA database: Signal 6: abort and Signal 11: segmentation fault, leading to service crash|SIGNAL 11|SIGSEGV|caught
Basis|Helper.cpp|Using x64_64 ABI unwind for stack tracing||2313619|This information is written in context of call stack generation, e.g. in case of a SAP HANA crash.|x64_64 ABI unwind|for stack tracing|
Basis|KernelProfiler.cpp|Error: Profiler systemTime: <ts1> -> <ts2> (-<ts3>)||1804811|This message is written by the kernel profiler due to a bug. It is fixed with SAP HANA >= 1.00.122.10 and >= 2.00.012.|Error|Profiler systemTime|
Basis|KernelProfiler.cpp|Error: Profiler userTime: <ts1> -> <ts2> (-<ts3>)||1804811|This message is written by the kernel profiler due to a bug. It is fixed with SAP HANA >= 1.00.122.10 and >= 2.00.012.|Error|Profiler userTime|
Basis|KernelProfiler.cpp|Error: Profiler waitTime: <ts1> -> <ts2> (-<ts3>)||1804811|This message is written by the kernel profiler due to a bug. It is fixed with SAP HANA >= 1.00.122.10 and >= 2.00.012.|Error|Profiler waitTime|
Basis|ProcessExecution.cpp|Child process exited: 255, "<command>" "<param1>" "<param2>" ...|||This information is printed when a child process (e.g. an external command like sldreg) is terminated with an error.|Child process exited|255|
Basis|ProcessorInfo.cpp|Using GDT segment limit to determine current CPU ID||1999880|Information messages displayed when a process is started or hdbnsutil connects to the nameserver|Using GDT segment limit to determine current CPU ID||
Basis|Timer.cpp|Fallback to system call for HR timer||2100040|The operating system call __vdso_gettimeofday is a slower fallback mechanism to retrieve time information when RDTSC isn't properly available for SAP HANA. In order to avoid this overhead you need to make sure that RDTSC (Read Time Stamp Counter) is properly configured on Linux level.|Fallback to system call for HR timer||
Basis|Timer.cpp|Using RDTSC for HR timer||1999880|Information messages displayed when a process is started or hdbnsutil connects to the nameserver|Using RDTSC for HR timer||
Basis|TopologyUtil.cpp|called by user '<os_user>' with UID: <uid> command: /<path>/hdbnsutil <options> parent process command line '<command>' with PID: <pid> parent process executable '<executable>'||1999880|Tracking of hdbnsutil calls of external processes like sapdbctrl in the nameserver trace file nameserver_<host>.00000.<counter>.trc, e.g. for monitoring system replication|called by user|with UID|parent process command line
Basis|TopologyUtil.cpp|called by user '<os_user>' with UID: <uid> command: /<path>/hdbnsutil <options> parent process command line '<command>' with PID: <pid> parent process executable '<executable>'||1999880|Tracking of hdbnsutil calls of external processes like sapdbctrl in the nameserver trace file nameserver_<host>.00000.<counter>.trc, e.g. for monitoring system replication|called by user|with UID|parent process executable
Basis|TraceStream.cpp|MaxOpenFiles: 1048576 Server Mode: L2 Delta ==== Starting hdb<service>, version <version>||2177064|General information during startup of a specific SAP HANA service or connection of hdbnsutil to nameserver process|MaxOpenFiles|1048576 Server Mode|L2 Delta
bw_datastore|DSOActivation.cpp|Potential performance problem: Table <schema>:/BIC/A<providername>00 is split and table <schema>:BIC/A<providername>40 is split by an appropriate criterion but corresponding parts are located on different servers. This will not prevent the Data Store from working but it may significantly degrade performance.|T1100|2158927|Inconsistent BW table partitioning and distribution|Potential performance problem|is split by an appropriate criterion but corresponding parts are located on different servers|
bw_datastore|DSOActivation.cpp|Potential performance problem: Tables <schema>:<table> and <schema>:<table> are split by unfavorable criteria. This will not prevent the Data Store from working but it may significantly degrade performance.|T1100|2158927|Inconsistent BW table partitioning and distribution|Potential performance problem|are split by unfavorable criteria|
CalcEngine|ceCalcScenarioHandler.cpp|There is neither a default value nor a data input mapping for the mandatory variable $$<variable>$$ of the scenario <schema>:<scenario> (t <id>) (see SAPNote 2525644 for more details).|T0222|2525644|Starting with SAP HANA 2.0 SPS 03 a stricter input variable check is introduced in context of stacked calculation scenarios that can result in query terminations and this database trace entry.|There is neither a default value nor a data input mapping for the mandatory variable|of the scenario|
CalcEngine|ceInstantiationHandler.cpp|CalcEngine Exception: exception <exception>: Undefined variable: <variable>. Variable is marked as required but not set in the query|T0224|2000002|This error is issued in case a calculation view is called and a required parameter isn't specified.|CalcEngine Exception|Undefined variable|Variable is marked as required but not set in the query
CalcEngine|ceManager.cpp|The following errors occurred: Inconsistent calculation model (34011) Details (Errors): <error_details>|T0226||This message indicates that a problem with a calculation model was found. Various SAP Notes exist that cover specific problem scenarios. You can search for them with search term  "Inconsistent calculation model (34011)".|The following errors occurred|Inconsistent calculation model|34011
CalcEngine|ceMetadataProviderImpl.cpp|<num> partitioned execution scopes detected in view <view>'. Only exactly one scope is supported.|||This message is printed during calculation view metadata access if more or less than 1 partitioned table is involved. It is harmless and can be ignored. New SAP HANA Revisions will no longer print this message.|partitioned execution scopes detected in view|partitioned execution scopes detected in view|
CalcEngine|ceNodeInstantiate.cpp|CalcEngine Exception: exception 306002: An internal error occurred|||This error indicates that an internal error has occurred in context of the calculation engine. You can check related trace file entries for further details about the actual error.|CalcEngine Exception|exception 306002|An internal error occurred
CalcEngine|ceRepositoryAccessor.cpp|RepositoryAccessor::getCalculationScenario(): for scenario '<scenario>' failed|T0228|2081505|This error indicates a problem when accessing a specific calculation scenario.|RepositoryAccessor|getCalculationScenario|for scenario
CalcEngine|ceUtils.cpp|Could not get template scenario '<scenario>' from ceManager|T0230|2580778|This error is typically caused by a SAP HANA bug that is fixed with SAP HANA >= 1.00.122.11 and >= 2.00.012.|Could not get template scenario|from ceManager|
ceExecute|cePopBase.cpp|Failed to find source column <column> in input itab: <table>|T0232|2413040|This error indicates a missing column that is typically caused by a problem on application side.|Failed to find source column|in input itab|
ceOptimizerInfo|ceCalcScenarioModelerInternal.cpp|Scenario '<scenario>' consistencyCheck: <details>|||This message provides details about a calculation scenario, typically in context of an error.|Scenario|consistencyCheck|
cePlanExec|cePlanExecutor.cpp|Error during Plan execution of model <model>, reason: <reason>|T0234|1999997|The processing of a calculation model was terminated with an error|Error during Plan execution of model|reason|
ceQo|ceQOBuilder.cpp|No output exp found from input to output mapfinalAggregation||2445102 2471313|This termination is linked to calculation views with currency conversion. The error is fixed with SAP HANA >= 1.00.122.09 and >= 2.00.001.|No output exp found from input to output mapfinalAggregation||
ceQo|ceQOBuilder.cpp|Root qo_project col count is different as expected: expected count: <val>, actual count: <val>|||This message indicate that unfolding of a calculation view isn't possible because it would impose the risk of wrong results. The actual query doesn't terminate, instead it is processed without unfolding.|Root qo_project col count is different as expected|expected count|actual count
ContainerDirecto|FileIDMapping.cpp|Loading <num_mappings> file ID mappings finished in <seconds> seconds||2222217|Load of container directory from disk, increased runtime in case of many disk LOBs or disk I/O bottlenecks|Loading|file ID mappings finished in|seconds
ContainerDirecto|VirtualFileStatsProxy.cpp|Initialize LOB owner statistics from VirtualFiles...||2222217|Disk LOB (SAP Note 2220627) initialization during startup|Initialize LOB owner statistics from VirtualFiles||
ContainerDirecto|VirtualFileStatsProxy.cpp|LOB owner statistics initialized from VirtualFile: <entries> CD entries in <minutes> min||2222217|Disk LOB (SAP Note 2220627) initialization during startup|LOB owner statistics initialized from VirtualFile|CD entries in|
CryptoSSFS|RawRootKeyStoreAccessor.cpp|RSecSSFs: SSFS-3600: Record "<record>" was inserted with an encryption key that was different from the current one; when you still know the old one, you can try the "migrate" operation of the "rsecssfx" utility|T0925|2097613 2618024|This error indicates that the secure store (SSFS) is inconsistent.|RSecSSFs|SSFS-3600|was inserted with an encryption key that was different from the current one; when you still know the old one
cs_ddl|DDLRequest.cp|Have invalid table for <database>::<schema>:<table>|T0243||This error indicates that a table is invalid, e.g. because a temporary table / temp index can't be found (e.g. during procedure execution).|Have invalid table for||
cs_statistics|CS_StatisticsImpl.cpp|expect non-empty top-k info for non-empty column in main: <schema>:<table> (t <id>).<column>||2089847|This is a typically harmless warning that TOP <n> statistics can't be used for a potentially better execution plan.|expect non-empty top-k info for non-empty column in main||
Daemon|Backint.cpp|Backint process <pid> not found in process list!||2506137|This is actually no error and indicates that the backint process has already finished. Starting with SAP HANA 2.0 this message is no longer displayed.|Backint process|not found in process list|
Daemon|NetworkConnection.cpp NetworkListener.cpp|closing connection finished channel <channel>||2222200|Processing of network requests by daemon service, purely informational messages|closing connection finished channel||
Daemon|NetworkConnection.cpp NetworkListener.cpp|closing connection channel, state FINISHED <channel>||2222200|Processing of network requests by daemon service, purely informational messages|closing connection channel|state FINISHED|
Daemon|NetworkConnection.cpp NetworkListener.cpp|Connection from <host>/<port>_tcp ... socket <socket> handled message of type "<type>", shall return <bytes> bytes||2222200|Processing of network requests by daemon service, purely informational messages|Connection from|handled message of type|shall return
Daemon|NetworkConnection.cpp NetworkListener.cpp|finishing connection channel <channel>||2222200|Processing of network requests by daemon service, purely informational messages|finishing connection channel||
Daemon|NetworkConnection.cpp NetworkListener.cpp|New connection accepted from <host>/<port>_tcp over socket <socket>||2222200|Processing of network requests by daemon service, purely informational messages|New connection accepted from|tcp over socket|
Daemon|TrexDaemon.cpp|current soft/hard limit of core file size (core) is <soft>/<hard>|T8001 until T8020|2600030|Operating system limitations for SAP HANA processes|current soft|hard limit of core file size|core
Daemon|TrexDaemon.cpp|current soft/hard limit of cpu time (cpu) is <soft>/<hard>|T8001 until T8020|2600030|Operating system limitations for SAP HANA processes|current soft|hard limit of cpu time|cpu
Daemon|TrexDaemon.cpp|current soft/hard limit of data seg size (data) is <soft>/<hard>|T8001 until T8020|2600030|Operating system limitations for SAP HANA processes|current soft|hard limit of data seg size|data
Daemon|TrexDaemon.cpp|current soft/hard limit of file size (fsize) is <soft>/<hard>|T8001 until T8020|2600030|Operating system limitations for SAP HANA processes|current soft|hard limit of file size|fsize
Daemon|TrexDaemon.cpp|current soft/hard limit of max locked memory (memlock) is <soft>/<hard>|T8001 until T8020|2600030|Operating system limitations for SAP HANA processes|current soft|hard limit of max locked memory|memlock
Daemon|TrexDaemon.cpp|current soft/hard limit of max user processes (nproc) is <soft>/<hard>|T8001 until T8020|2600030|Operating system limitations for SAP HANA processes|current soft|hard limit of max user processes|nproc
Daemon|TrexDaemon.cpp|current soft/hard limit of open files (nofile) is <soft>/<hard>|T8001 until T8020|2600030|Operating system limitations for SAP HANA processes|current soft|hard limit of open files|nofile
Daemon|TrexDaemon.cpp|current soft/hard limit of resident set size (rss) is <soft>/<hard>|T8001 until T8020|2600030|Operating system limitations for SAP HANA processes|current soft|hard limit of resident set size|rss
Daemon|TrexDaemon.cpp|current soft/hard limit of stack size (stack) is <soft>/<hard>|T8001 until T8020|2600030|Operating system limitations for SAP HANA processes|current soft|hard limit of stack size|stack
Daemon|TrexDaemon.cpp|current soft/hard limit of virtual memory (as) is <soft>/<hard>|T8001 until T8020|2600030|Operating system limitations for SAP HANA processes|current soft|hard limit of virtual memory|
Daemon|TrexDaemon.cpp|process hdb<service> with pid <pid> exited because it caught signal <signal>||2177064|Service termination|process hdb|with pid|exited because it caught signal
DaemonClient|Network.cpp|Message "<message>". Daemon pid <pid>. Child pid <pid>|||This information message provides details about daemon requests from another SAP HANA service (e.g. indexserver). <message> is e.g. 'started', 'wait for pid' or 'execute backint'.|Message|Daemon pid|Child pid
DaemonClient|Network.cpp|Message "<message>". Daemon pid <pid>. Child pid <pid>|||This information message provides details about daemon requests from another SAP HANA service (e.g. indexserver). <message> is e.g. 'started', 'wait for pid' or 'execute backint'.|Message|Received|bytes
DaemonClient|NetworkLinux.cpp|KeepAlive parameters: TCP_KEEPIDLE=600 TCP_KEEPCNT=5 TCP_KEEPINTVL=10||2222200|Network keep alive settings used for communications between daemon and other SAP HANA service. With newer SAP HANA Revisions this info message is no longer written to the trace files with the default trace level.|TCP_KEEPIDLE||
DaemonClient|NetworkLinux.cpp|KeepAlive parameters: TCP_KEEPIDLE=600 TCP_KEEPCNT=5 TCP_KEEPINTVL=10||2222200|Network keep alive settings used for communications between daemon and other SAP HANA service. With newer SAP HANA Revisions this info message is no longer written to the trace files with the default trace level.|TCP_KEEPCNT||
DaemonClient|NetworkLinux.cpp|KeepAlive parameters: TCP_KEEPIDLE=600 TCP_KEEPCNT=5 TCP_KEEPINTVL=10||2222200|Network keep alive settings used for communications between daemon and other SAP HANA service. With newer SAP HANA Revisions this info message is no longer written to the trace files with the default trace level.|TCP_KEEPINTVL||
dbapiRequestProc|RequestProcessor.cpp|Failed to retrieve connection <conn_id>|||This is typically a consequence of other errors, e.g. terminations with "The execution of the script has exceeded the maximum request runtime".|Failed to retrieve connection||
DeltaLog_Replaye|Replay.cpp|Persistency before HANA 1.0 SP10 is not supported since HANA 2.0. Please contact database support for further instructions. Cannot load table <schema>:<table> in online transaction due to too old persistence format from before SP9|T0490|2372809|This error is written when the persistence format of a table isn't properly migrated to SAP HANA 2.0. Make sure that the migration is executed based on the instructions in SAP Note 2372809.|Persistency before HANA 1.0 SP10 is not supported since HANA 2.0. Please contact database support for further instructions. Cannot load table|in online transaction due to too old persistence format from before SP9|
DeltaLog_Replaye|Replay.cpp|Cannot create delta for table that is not yet visible in a separate transaction|T0430||This error indicates an inconsistent metadata state. It typically appears in context of business activities involving significant TRUNCATE operations like BW data loads. Workarounds and solutions are: -   Check if a temporary RENAME of the table fixes the inconsistency. -Upgrade to SAP HANA >= 1.00.122.16, >= 2.00.012.02, >= 2.00.021 or 2.00.030 where a related bug is fixed. -Clear the SQL cache (SAP Note 2124112) so that inconsistent metadata information is purged. -If corrupted tables are empty: Drop / recreate them in order to recreate metadata from scratch.|Cannot create delta for table that is not yet visible in a separate transaction||
delta_merge|DeltaIndexManager.cpp|Caught exception merging attributes|T0815|2057046|This error indicates that a table optimization was interrupted, e.g. due to a cancel request.|Caught exception merging attributes||
delta_merge|TRexApiAdmin.cpp|Transaction canceled during persistence operation||2057046|This error indicates that a table optimization was cancelled while performing a persistence operation.|Transaction canceled during persistence operation||
EmbeddedAPI|Statement.cc|unhandled ltt exception was caught: conn_id=<conn_id>, stmt_id=<statement_id>, stmt_hash=<statement_hash>, error=Query Canceled, sql=<sql_text>||2092196|This error can be recorded if a database request is cancelled. It doesn't indicate a specific problem apart from the cancellation.|unhandled ltt exception was caught|Query Canceled|
Environment|Environment.cpp|Changing environment set <variable>=<value>||2358255|Normal warning when environments settings are changed, e.g. during process startup|Changing environment set||
Environment|NetworkListener.cpp|Child process deletes daemon port||2358255|Normal warning in daemon trace when services are (re-)started or requests arrive at daemon service|Child process deletes daemon port||
EmbeddedAPI|Connection.cc|exceed 90% of max connection limit: current <current_connections>, limit <max_connections>|T2010|2154870|Number of existing connections reaching 90 % of allowed connections (typically 65536)|exceed|of max connection limit|limit
EmbeddedAPI|Connection.cc|exception  1: no.7400000 Internal error in hex engine: Please open a ticket and include the service trace files which cover the time of the query execution.|T0240|2570371|This error indicates that an internal error in the SAP HANA Execution Engine (HEX) has happened. Please open a SAP incident on component HAN-DB in order to request assistance. Attach the related database trace files (typically the indexserver trace, SAP Note 2380176) with the error details. As a temporary workaround you can disable HEX: indexserver.ini -> [sql] -> hex_enabled = false. In order to make sure that existing SQL statements are reparsed without using HEX, you may have to clear the plan cache or remove explicitly known plan cache entries (SAP Note 2124112): ALTER SYSTEM CLEAR SQL PLAN CACHE. ALTER SYSTEM REMOVE SQL PLAN CACHE ENTRY '<plan_id>'|Internal error in hex engine|Please open a ticket and include the service trace files which cover the time of the query execution|
EmbeddedAPI|Connection.cc|exception  1: no.10001001: internal error: message=Search result size limit exceeded|T2000|2154870|Intermediate result set size exceeds 4 billion records, responsible database request needs to be checked and optimized (SAP Note 2000002)|10001001|internal error|Search result size limit exceeded
EmbeddedAPI|Connection.cc|exception  1: no.71000000: Invalid forwarding to datacenter; $monitor$=<monitor_view>|T0564|2222200|This error indicates that a request to a system replication data center failed. Typical reasons are communication problems (SAP Note 2222200) and issues on secondary / tertiary system replication site (SAP Note 1999880). This scenario happens in context of monitoring view accesses that implicitly access remote sites.|71000000|Invalid forwarding to datacenter|
EmbeddedAPI|Statement.cc|unhandled ltt exception was caught: conn_id=<conn_id>, stmt_id=<statement_id>, stmt_hash=<statement_hash>, error=Search result size limit exceeded: $rs$, sql=<sql_text>|T2000|2154870|Intermediate result set size exceeds 4 billion records, responsible database request needs to be checked and optimized (SAP Note 2000002)|unhandled ltt exception was caught|error|Search result size limit exceeded
esh|BuiltinProcedureSearch.cpp|ESH_SEARCH error: "error":{"code":"<code>","message":"exception <code>: <error>}|T0238|2347563|This message indicates an enterprise search termination, root cause and resolution depends on the reported <error>, e.g.: - 9620057: Column "<column>" cannot be used in aggregation, since type "NCLOB" can not be aggregated - 9620106: Error in $apply: syntax error, unexpected SIGN, expecting CLOSE or WHITE_SPACE (SAP Note 2347563) - 71002048: search table error: [2018] Option 'textSearch' not allowed for column <column>|ESH_SEARCH error||
euclid|AttributeApi.cpp|getOpenIndex(<schema>:<table> (t <id>)) failed||2127458|This error indicates that it wasn't possible to open a table. This is typically a consequence of an error during column load.|getOpenIndex|failed|
eval|Evaluator.cpp|expressionToQueryEntries failed to convert '<value>' parse('<value>') Evaluator: syntax error in expression string;expected <expected_value>',parsing '<parsed_value>'(6968)|T0206|2394478|This error can happen as a consequence of problems on application or modelling side.|expressionToQueryEntries failed to convert|Evaluator|syntax error in expression string
EventHandler|EventManagerImpl.cpp|acknowledge: SystemReplicationEvent: Site <site_id>: AutoEventHandlerCallback::initial(period= 60)Communication channel closed|T1200|1999880|An event reporting a disconnection to the secondary system replication site is reported / acknowleged on primary site.|SystemReplicationEvent|AutoEventHandlerCallback|Communication channel closed
Executor|PlanExecutor.cpp|[2629] executor: plan terminated internally after being inactive for too long(2048)|T0208|2584706|This error indicates that a plan operation was inactive for more than the configured termination thresholds and so the execution was terminated.|executor|plan terminated internally after being inactive for too long|
Executor|PlanExecutor.cpp|end executor returns||2020877|These comments frame the actual details that are printed to the trace when a plan execution fails.|end executor returns||
Executor|PlanExecutor.cpp|returns for plan||2020877|These comments frame the actual details that are printed to the trace when a plan execution fails.|returns for plan||
Executor|PlanExecutor.cpp|calculateSingleThreaded plan <plan> failed with rc <rc>|||This error indicates that a single threaded plan execution terminated with an error. Return codes can be for example: 70006892 (message not found)|calculateSingleThreaded plan|failed with rc|
Executor|PlanExecutor.cpp|column search intermediate result exceeds 2 billion rows limitation|T2001|2154870|This error is thrown if an intermediate column search result exceeds the limit of 2 billion rows.|column search intermediate result exceeds 2 billion rows limitation||
Executor|PlanExecutor.cpp|invalid character encoding|T0210|2478767|This error indicates a problem with the encoding / conversion of characters. Known issues are: -Accesses to passport columns in thread samples view (SAP Note 2478767), fixed with >= 1.00.122.12, >= 2.00.012.01 and >= 2.00.021. -Wrong character handling in context of ptime::qo_Conj::disambiguate, just an internal error without a termination of the related request, fixed with >= 1.00.122.15 and >= 2.00.012.04.|invalid character encoding||
Executor|PlanExecutor.cpp|olap: merging multi value dicts is not implemented|T0212|1866135|This error is caused by an underlying issue like a modelling deficiency or a corruption.|olap|merging multi value dicts is not implemented|
Executor|PlanExecutor.cpp|Query Canceled(139), plan: <id>/<total> pops: ...||2092196|These errors indicate that plan execution is cancelled (e.g. due to manual request or timeout).|Query Canceled|plan|pops
Executor|PlanExecutor.cpp|rc 301; unique constraint violated TrexUpdate failed on table '_SYS_STATISTICS:<table>'|T0101|2147247|Unique constraint issue on statistics server table|unique constraint violated TrexUpdate failed on table|_SYS_STATISTICS|rc 301
Executor|PlanExecutor.cpp|rc 314, search table error: [6944] AttributeEngine: overflow in numeric calculation|T0200|2559741|This error indicates that a database request had to be terminated because the numeric value range was exceeded, e.g. because the sum of integer values exceeded 4 billion. If it happens when accessing HOST_DELTA_MERGE_STATISTICS_BASE, SAP Note 2559741 may be relevant.|rc 314|search table error|overflow in numeric calculation
Executor|X2OldLock.cpp|failed to send listPlan request to <host>:<port> an error occured while reading from the channel|T0556|2546137|If this errors happen after a failover, it is typically harmless and can be ingored.|failed to send listPlan request to|an error occured while reading from the channel|
Executor|X2OldLock.cpp|failed to send listPlan request to <host>:<port> an error occured while opening the channel|T0556|2546137|If this errors happen after a failover, it is typically harmless and can be ingored.|failed to send listPlan request to|an error occured while opening the channel|
Executor|X2OldLock.cpp|runPopTask(): plan data for input is null while trying to call setIsShared()|||Seen without other related trace entries, this superfluous entry is caused by a time dependent problem in distributed queries, it may not have any impact on the application queries. It is fixed with SAP HANA >= 2.00.001.|runPopTask|plan data for input is null while trying to call setIsShared|
expr|ExpressionParser.cpp|parse error Evaluator: syntax error in expression string||2057046|This error is issued in case an expression can't be parsed properly, e.g. in context of erroneously configured delta merge and optimize compression decision functions.|parse error Evaluator|syntax error in expression string|
ExprConversionTo|ConvertExpression.cpp|error with message: % and _ are special character in SQL LIKE. In this case we need to add LIKE with ESCAPE but it cannot be converted due to missing info|||This message is printed when expressions with placeholder characters like '_' or '%' are used in context of LIKE and calculation engine executions. This issue won't result in a query termination, but it can be responsible for performance overhead because certain features like unfolding may not be used. With newer SAP HANA Revision levels the underlying limitation no longer exists.|error with message|are special character in SQL LIKE|In this case we need to add LIKE with ESCAPE but it cannot be converted due to missing info
ExprConversionTo|ConvertExpression.cpp|error with message: Convert error"<expression>"|T0213||This error indicates that an expression can't be converted. Based on the related TraceContext entries in the trace file you can determine the related user and database request so that you can analyze and adjust the conversion.|error with message|Convert error|
ExprConversionTo|ConvertExpression.cpp|error with message: Expression conversion is failed in <expression1> = <expression2>|T0214||This error indicates that an expression can't be converted. Based on the related TraceContext entries in the trace file you can determine the related user and database request so that you can analyze and adjust the conversion.|error with message|Expression conversion is failed in|
failover|DistributedWatchDog.cpp LocalWatchDog.cpp|In context of host auto-failover (SAP Note 2057595) the availability of processes like the nameserver are checked on a regular basis by the watchdog. If this check isn't answered in time, this warning is issued. It can indicate problems in the network area or the unavailability of a SAP HANA service. The interval can be configured via (only recommended in exceptional cases based on advice by SAP support): nameserver.ini -> [distributed_watchdog] -> interval = <seconds> (default: 10) and nameserver.ini -> [local_watchdog] -> interval = <seconds> (default: 10).||2222200|In context of host auto-failover (SAP Note 2057595) the availability of processes like the nameserver are checked on a regular basis by the watchdog. If this check isn't answered in time, this warning is issued. It can indicate problems in the network area or the unavailability of a SAP HANA service. The interval can be configured via (only recommended in exceptional cases based on advice by SAP support): nameserver.ini -> [distributed_watchdog] -> interval = <seconds> (default: 10)|pingNameServer|Communication problem or interval|
FedTrace|odbcaccess.cpp|ODBC error: connected: <num> state: <state> code: -<error_code> [Sybase][ODBC Driver][SQL Anywhere] <error_description>|T1300|2180119|These errors indicate errors when communicating with Sybase IQ, e.g. in context of smart data access (SDA, SAP Note 2180119). Typical errors are: -85 / Communication error: The communication with Sybase IQ wasn't possible. -100 / Database server not found: The Sybase IQ database server couldn't be reached. -141 / Table <table> not found: A specific table wasn't found on Sybase IQ side. -299 / Statement interrupted by user: A Sybase IQ request was terminated on client side.|ODBC error|Sybase|SQL Anywhere
FedTrace|odbcaccess.cpp|ODBC error: connected: <num> state: <state> code: -<error_code> [Sybase][ODBC Driver][Sybase IQ] <error_description>|T1300|2180119|These errors indicate errors when communicating with Sybase IQ, e.g. in context of smart data access (SDA, SAP Note 2180119). Typical errors are: -85 / Communication error: The communication with Sybase IQ wasn't possible. -100 / Database server not found: The Sybase IQ database server couldn't be reached. -141 / Table <table> not found: A specific table wasn't found on Sybase IQ side. -299 / Statement interrupted by user: A Sybase IQ request was terminated on client side.|ODBC error|Sybase|Sybase IQ
FileIO|Filesystem.cpp|Unsupported file system "<file_system_type>" for "<directory>/<file>"|T0620|1999930|Warning that used filesystem type isn't supported. With SAP HANA <= 2.0 SPS 01 standby nodes are unnecessarily checked what can cause irrelevant errors. These messages are suppressed starting with SAP HANA 2.0 SPS 02.|Unsupported file system||
FileIO|FileStatistics.cpp|CompletionQueueConfiguration::initial ... num_completion_queues ... size_kernel_io_queue||1999930|I/O queue configuration and filesystem related parameter settings|CompletionQueueConfiguration::initial|num_completion_queues|size_kernel_io_queue
FileIO|FileStatistics.cpp|SubmitQueueConfiguration::initial ... num_submit_queues ... size_kernel_io_queue||1999930|I/O queue configuration and filesystem related parameter settings|SubmitQueueConfiguration::initial|num_submit_queues|size_kernel_io_queue
FileIO|FileStatistics.cpp|FileFactoryConfiguration::initial ... async_write_submit_active ... async_write_submit_blocks||1999930|I/O queue configuration and filesystem related parameter settings|FileFactoryConfiguration::initial|async_write_submit_active|async_write_submit_blocks
FREESTYLE|FreeStyleMetaData.cpp|freestyle attribute list is empty!|T0216||Termination of text search due to empty attribute list|freestyle attribute list is empty||
ha_dr_provider|PythonProxyImpl.cpp|vIPMover/vIPMover:startup() failed with python error: Usage of subprocess/popen2 not allowed in invoked python coding|T1900|2615046|This message is issued when subprocess or popen2 is used in Python context. Instead popen or system should be used.|vIPMover|failed with python error|popen2 not allowed in invoked python coding
HistoryManager|HistoryManager.cpp|Maximum garbage collection parallelity set to <degree>||2169283|Persistence garbage collector parallelity, based on max_gc_parallelity setting|Maximum garbage collection parallelity set to||
ImportExport|ImportExport.cpp|Import has failed during checking its feasibility|T1310|2222277|This error indicates a problem during table import. Details are usually reported in a separate line (e.g. "Invalid column store version match").|Import has failed during checking its feasibility||
ImportExport|ImportExportHelper.cpp|Invalid column store version match, current=unknown (<id>), source=unknown (<id>)|T1315|2222277|This error indicates that a table from a source system with incompatible SAP HANA version can't be imported.|Invalid column store version match|current|source
JavaScript|SandBox.cpp|Failed to close $.db.Connection: $ERROR_TYPE$: $ERROR_MESSAGE$|||Problems closing a JavaScript connection, e.g. in context of other errors like. This is typically a consequence of other errors, e.g. terminations with "The execution of the script has exceeded the maximum request runtime.|Failed to close|ERROR_TYPE|ERROR_MESSAGE
Job|JobExecutorUtil.cpp|dubious configuration detected, switching to single numa node mode: <log_cpu> log.CPUs, <act_cpu> active, <phys_cpu> phys.cores, <sockets> sockets running as VM guest log.CPU <cpu_id> core index <core_id> socket index <socket_id>|T0320|2470289|These errors indicate that the underlying NUMA configuration is considered as inappropriate by SAP HANA. Make sure that the NUMA configuration on OS / virtualization layer is implemented correctly. For VMware vSphere environments you can check the recommendations at SAP HANA on VMware vSphere for details.|dubious configuration detected|switching to single numa node mode|log.CPUs
join_eval|Estimator.cpp|exec estimation failed rc=<rc> error=<error>|||This error indicates that the join engine estimation failed for a specific database request. The actual root cause depends on the return code / error.|exec estimation failed rc|error|
join_eval|JECreateNTuple.cpp|plan aborted; $function$=recurse; $message$=abort plan||2092196|This message indicates that a join engine plan execution was aborted, e.g. due to a cancel request of the end user or the MVCC anti ager.|plan aborted|recurse|abort plan
join_eval|JEPlanOperation.cpp|Caught exception in pop <plan_operation>||2000002|This message indicates an error when executing a plan operation in the join engine.|Caught exception in pop||
join_eval|JEPlanOperation.cpp|content of planData ... Inputs of failed pop ... planData <id>: JEPlanData|||These lines contain analysis details in context of join engine terminations. The actual error can be found in other trace file lines (e.g. rc=2625 for user cancellation).|content of planData|Inputs of failed pop|JEPlanData
join_eval|JoinEvaluator.cpp|MGetEstimations failed for query part <id>|||This error indicates a termination while performing estimations (e.g. in context of query optimization). The detailed error can be found in related trace file lines (e.g. "attribute value is not a date or wrong syntax" or "Attribute engine function not implemented").|MGetEstimations failed for query part||
join_eval|JoinEvaluator.cpp|removing plan from cache||2124112|This message indicates that an SQL plan is removed from the cache. It typically happens in context of a termination during join engine processing (e.g. cancellation).|removing plan from cache||
join_eval|JoinViewUnfolder.cpp|Assertion failed: (join->get_join_type() == qoJoinType); lhs: 3; rhs: 0; message: All join types must be the same||2413854 2405803|This message is not critical and will no longer be displayed with SAP HANA >= 1.00.122.06 and >= 2.00.001.|Assertion failed|qoJoinType|All join types must be the same
join_eval|MGetEstimations.cpp|estimateParallel failed rc=<rc>||2361364|This error indicates a termination while performing estimations (e.g. in context of query optimization). The detailed error can be found in related trace file lines and is linked to the indicated return code (e.g. "attribute value is not a date or wrong syntax" for rc=6931 or "Attribute engine function not implemented" for rc=6901).|estimateParallel failed rc||
KernelSentinel|KernelSentinelJob.cpp|Table replication will be turned off as the following top 10 transactions which access the replicated tables are waiting synchronous commit(OSTR) or rollback(OSTR/ATR) over <timeout> seconds|T2110|2340450|This message indicates that table replication is deactivated for specific tables because the configured <timeout> (default: 600 s) was exceeded by an update transaction accessing the table replica. See SAP Note 2340450 ("What are reasons for deactivation of table replication?" -> "Uncommitted transaction timeout") for details.|Table replication will be turned off as the following top 10 transactions which access the replicated tables are waiting synchronous commit|OSTR|
Licensing|LicenseEAPIUtils.cpp|Enter virtual EAPI::ConnectionHandle Licensing::LicenseEAPIUtils::getConnection()||1704499|These messages are linked to license measurement. Normally they are not printed to the traces, but in some SAP HANA Revisions an increased trace level was delivered in order to support troubleshooting.|Enter virtual EAPI|ConnectionHandle Licensing|LicenseEAPIUtils
Licensing|LicenseEAPIUtils.cpp|Enter virtual void Licensing::LicenseEAPIUtils::storeMeasurement||1704499|These messages are linked to license measurement. Normally they are not printed to the traces, but in some SAP HANA Revisions an increased trace level was delivered in order to support troubleshooting.|Enter virtual void Licensing|LicenseEAPIUtils|storeMeasurement
Licensing|LicenseEAPIUtils.cpp|Exit virtual EAPI::ConnectionHandle Licensing::LicenseEAPIUtils::getConnection()||1704499|These messages are linked to license measurement. Normally they are not printed to the traces, but in some SAP HANA Revisions an increased trace level was delivered in order to support troubleshooting.|Exit virtual EAPI|ConnectionHandle Licensing|LicenseEAPIUtils
Licensing|LicenseEAPIUtils.cpp|Exit virtual void Licensing::LicenseEAPIUtils::storeMeasurement||1704499|These messages are linked to license measurement. Normally they are not printed to the traces, but in some SAP HANA Revisions an increased trace level was delivered in order to support troubleshooting.|Exit virtual void Licensing|LicenseEAPIUtils|storeMeasurement
Licensing|LicensePluginRegistry.cpp|attempt to store <glas_id> at <date> ... Enter virtual void Licensing::LicensePluginRegistry::storeMemoryMeasurement ... Exit virtual void Licensing::LicensePluginRegistry::storeMemoryMeasurement ... Storing HANA measurement result: <glas_id>, ...||1704499|These messages are linked to license measurement. Normally they are not printed to the traces, but in some SAP HANA Revisions an increased trace level was delivered in order to support troubleshooting.|Enter virtual void Licensing|LicensePluginRegistry|
Licensing|LicensePluginRegistry.cpp|attempt to store <glas_id> at <date> ... Enter virtual void Licensing::LicensePluginRegistry::storeMemoryMeasurement ... Exit virtual void Licensing::LicensePluginRegistry::storeMemoryMeasurement ... Storing HANA measurement result: <glas_id>, ...||1704499|These messages are linked to license measurement. Normally they are not printed to the traces, but in some SAP HANA Revisions an increased trace level was delivered in order to support troubleshooting.|Exit virtual void Licensing|LicensePluginRegistry|
Licensing|LicensesMonitor.cc|No plugin found for license product <product>||2445080|This error is written when M_LICENSES is queried and it contains a PRODUCT_NAME (e.g. SAP-HANA-DT, SAP-HANA-EPM, SAP-HANA-SDS or SAP-HANA-SYNC) without an appropriate license plugin. There are different reasons for this scenario, e.g.: - Not all product SAP HANA related license plugins available in running SAP HANA database - Native products like enterprise performance management (EPM) or dynamic tiering (DT) only registered the plugin at the time when they were installed. If the license was installed earlier, the error could be reported. - External products like smart data streaming (SDS) or remote data sync (SYNC) generally didn't register plugins. This error only impacts license measurements and has no negative impact on the business load. Starting with SAP HANA 2.0 SPS 02 all SAP HANA related product license plugins are always available so that the error traces are no longer reported.||No plugin found for license product|
Licensing|LicensesMonitor.cc|No valid measurement could be obtained for HANA after retry||2445080|This error is written when M_LICENSES is queried and it contains a PRODUCT_NAME (e.g. SAP-HANA-DT, SAP-HANA-EPM, SAP-HANA-SDS or SAP-HANA-SYNC) without an appropriate license plugin. There are different reasons for this scenario, e.g.: - Not all product SAP HANA related license plugins available in running SAP HANA database - Native products like enterprise performance management (EPM) or dynamic tiering (DT) only registered the plugin at the time when they were installed. If the license was installed earlier, the error could be reported. - External products like smart data streaming (SDS) or remote data sync (SYNC) generally didn't register plugins. This error only impacts license measurements and has no negative impact on the business load. Starting with SAP HANA 2.0 SPS 02 all SAP HANA related product license plugins are always available so that the error traces are no longer reported.||No valid measurement could be obtained for HANA after retry|
Lock|FineLock.cc|failed to acquire record lock. Too many waiting transactions: entry=(hold_count=65535 wait_count=1023 wait_promo_count=0 x_owner_tid=<utid> x_owner_stid=0 s_owners=)|T707|2154870|This error is issued in case of too many concurrent lock waiters. Consider reducing the parallelism on application side in order to minimize the concurrent waiters. Check if there is a general performance issue on the system that increases the probability of a high number of concurrent record locks. See SAP Note 1999998 for more information related to transactional SAP HANA locks.|failed to acquire record lock. Too many waiting transactions|hold_count|wait_count
Lock|WaitGraph.cc|Deadlock detected: Deadlock detected while executing transaction (TRANSACTION_ID=<tid>, UPDATE_TRANSACTION_ID=<utid>): This is not an HDB error. User or application may cause a deadlock due to incorrect access sequences on shared objects.|T0706|1999998|Deadlock was detected|Deadlock detected while executing transaction||
Lock|WaitGraph.cc|Lock timeout occurs while waiting RECORD_LOCK of mode EXCLUSIVE|T0702 T0704|1999998|A statement was terminated because of the lock timeout.|Lock timeout occurs while waiting RECORD_LOCK of mode EXCLUSIVE||
Lock|WaitGraph.cc|Lock timeout occurs while waiting OBJECT_LOCK of mode EXCLUSIVE|T0702 T0704|1999998|A statement was terminated because of the lock timeout.|Lock timeout occurs while waiting OBJECT_LOCK of mode EXCLUSIVE||
Logger|BackupHandlerImpl.cpp|Error during log segment backup: exception 1: no.3040120 ... Buffer checksum <checksum> stored at position 0 in segment <segment> invalid, calculated checksum <checksum2>|T0425|2628775|This error happens when an invalid checksum is calculated during log segment backups.|Error during log segment backup|Buffer checksum|stored at position 0 in segment
Logger|BackupHandlerImpl.cpp|Error during log segment backup: exception 1: no.110013 ... Unexpected end of backup, expected amount of data is <byte> but transferred <byte>|T1010|2222200|Problem performing a log backup typically caused by communication issues|Error during log segment backup|Unexpected end of backup|expected amount of data is
Logger|BackupHandlerImpl.cpp|Log segment backup failed with 5 retries, set backup history broken, trigger savepoint and mark segment as corrupt/incomplete||2628775|This error happens when repeatedly an invalid checksum is calculated during log segment backups. Per default this results in a log backup history gap and an emergency shutdown is triggered.|Log segment backup failed with|set backup history broken|trigger savepoint and mark segment as corrupt
Logger|LoggerImpl.cpp|Activating log backup, since initial data backup is about to start||1642148|Log backups aren't required as long as data backups can't be recovered properly. When the first data backup is taken, log backups also start and this message is written.|Activating log backup|since initial data backup is about to start|
Logger|LoggerImpl.cpp|primaryBackupFinished(<id>)||1642148|Indication that backup is finished|primaryBackupFinished||
Logger|LoggerImpl.cpp|Using log segment size <default>MB not possible due to buffer size constraint. Current value <adjusted>MB, current minimum <minimum>. Using <used>MB||2215131|This message can be displayed if the log_buffer_size parameter is increased and so certain size prerequisites have to be met for the log segment size, requiring and adjustment of the default segment size.|Using log segment size|MB not possible due to buffer size constraint|Current value
Logger|LogSegment.cpp|Free segment kept for replication, LogSegment... Try to free RETAINED_FREE segment as logshipping_max_retention_size reached||1999880|Handling of log segments in context of system replication scenarios with log_replay operation modes|Free segment kept for replication|LogSegment|
Logger|LogSegment.cpp|Free segment kept for replication, LogSegment... Try to free RETAINED_FREE segment as logshipping_max_retention_size reached||1999880|Handling of log segments in context of system replication scenarios with log_replay operation modes|Try to free RETAINED_FREE segment as logshipping_max_retention_size reached||
Logger|LogSegment.cpp|Opening new log segment LogSegment ... in LogPartition ...|||Redo log switch, typically caused by: -redo log full -Log backup timeout (global.ini -> [persistence] -> log_backup_timeout_s) reached|Opening new log segment LogSegment|in LogPartition|
Logger|PersistenceManagerImpl.cpp|set restart redo log position <pos>||2100009|Information about redo log restart position in context of savepoints|set restart redo log position||
Logger|RecoveryHandlerImpl.cpp|Recovery or restart successfully completed redo of log at log position <pos> within segment LogSegment[<id>/Writing,ts=<timestamp>] [GUID=<guid>/PrevGUID=<prev_guid>/ PersGUID=<pers_guid>/RestoreGUID=<rest_guid>] at file position <pos>, unused rest <id>, termination reason: Invalid buffer header found at position <pos> in segment <seg>||1642148|Although "Invalid buffer header found" seems to indicate a problem situation, this is only a standard information message that happens at the end of the log recovery when the most recent redo log information is reached and no additional log information is available. So there is no need to worry and you can assume that the log replay finished successfully.|Recovery or restart successfully completed redo of log at log position|termination reason|Invalid buffer header found at position
Logger|RecoveryHandlerImpl.cpp|Redo done up to position: <pos> and time: <time>||1642148|Status of log recovery|Redo done up to position||
Logger|RecoveryHandlerImpl.cpp|Termination of indoubt transactions. (raw page size in bytes to be still rolled back <byte> or garbage collected <byte>)||2222217|Rollback of open transactions after log replay during SAP HANA startup (after restore, crash or hard shutdown)|Termination of indoubt transactions|raw page size in bytes to be still rolled back|or garbage collected
Logger|PersistenceManagerImpl.cpp|Start garbage collection of history files||2169283|This message indicates that persistence garbage collection is started.|Start garbage collection of history files||
Logger|PersistenceManagerImpl.cpp|Termination of rollback(s) open in restart/backup savepoint. (undo size in bytes to be still rolled back <byte>)||2222217|Rollback of open transactions before log replay during SAP HANA startup (after restore, crash or hard shutdown)|Termination of rollback|backup savepoint|undo size in bytes to be still rolled back
Logger|RecoveryHandlerImpl.cpp|Triggering log recovery up to position <pos>||2222217|Recovery of redo logs during SAP HANA startup after crash or hard shutdown|Triggering log recovery up to position||
Logger|SavepointImpl.cpp|Savepoint #<id> waiting for critical phase for ~<seconds>s, Runtimdeump skipped because last Runtimedump was written <seconds> s ago.|T0712|2100009|This warning is written when the savepoint waitForLock phase has exceeded the runtime dump threshold (indexserver.ini -> [persistence] -> runtimedump_for_blocked_savepoint_timeout), but no runtime dump is written because a recent dump was already created (within the last 24 hours).|Savepoint|waiting for critical phase for|Runtimdeump skipped because last Runtimedump was written
Logger|SavepointImpl.cpp|Savepoint current savepoint version: <version>, restart redo log position: <pos>, next savepoint version: <version2>, last snapshot SP version: <version3>||2100009|Savepoint execution|Savepoint current savepoint version|restart redo log position|next savepoint version
LogReplay|RowStoreReplayMgr.cc|Reassign transTable(<id>)||1999880|This information message is printed in context of savepoints and logreplay activities (e.g. on secondary system replication sites operated with logreplay mode)|Reassign transTable||
LVCProcedure|LVCProcedure.cc|Execute of <schema>::<procedure> failed with OmsTerminate|T1400|2593571|Termination of a liveCache procedure (e.g. due to cancellation)|Execute of|failed with OmsTerminate|
LVC_Session|ConsoleError|OmsHandle::omsTerminate in method <procedure>|T1400|2593571|Termination of a liveCache procedure (e.g. due to cancellation)|OmsHandle|omsTerminate in method|
mds|CommonMessage.cpp|[42208] Can't read the view : <view>|||This error indicates that an MDS request couldn't be executed because of different general errors.|42208|read the view|
mds|CommonMessage.cpp|[42474] The view doesn't contain the measure : <measure>|||This error indicates that an MDS request couldn't be executed because of different general errors.|42474|The view doesn|t contain the measure
mds|CommonMessage.cpp|[42535] The member is already defined : <member>|||This error indicates that an MDS request couldn't be executed because of different general errors.|42535|The member is already defined|
mds|CommonMessage.cpp|[42567] Error during formula evaluation. : invalid calculation entity for MemberTuple|||This error indicates that an MDS request couldn't be executed because of different general errors.|42567|Error during formula evaluation|invalid calculation entity for MemberTuple
mds_expression|RefineTypeVisitor.cpp|invalid calculation entity for MemberTuple: [<member>]|||This error indicates a problem parsing a member tuple of an MDS request.|invalid calculation entity for MemberTuple||
mds_metadata|Reader.cpp|Error happened during callback execution to get EPM QUERY SOURCE metadata. This error is currently ignored.|||This is a general information in case an error happened when accessing metadata in MDS contexts, e.g. "[42208] Can't read the view".|Error happened during callback execution to get EPM QUERY SOURCE metadata|This error is currently ignored|
Memory|AllocatorImpl.cpp|Allocators activated||1999997|Memory information that is printed in initialization phases, e.g. when hdbnsutil connects to the nameserver or when a process starts up|Allocators activated||
Memory|AllocatorImpl.cpp|Using big block segment size 268435456||1999997|Memory information that is printed in initialization phases, e.g. when hdbnsutil connects to the nameserver or when a process starts up|Using big block segment size 268435456||
Memory|Memory.cp|Could not get some memory usage statistics from Cgroup, fetching from /proc/meminfo file||2694985|These messages are harmless and with SAP HANA 2.00.032 and 2.00.033 a lot of them can be written to the trace due to a SAP HANA bug.|Could not get some memory usage statistics from Cgroup|fetching from|
Memory|PoolAllocator.cpp|[allocator contains <blocks> blocks, in total <byte>B]|T0312|2580435|This message indicates that leaked memory was found that is automatically cleaned up. This scenario can be a consequence of a SAP HANA bug in context of fast data access (FDA).|allocator contains|blocks|in total
Memory|PoolAllocator.cpp|Block list (including suballocators)|T0312|2580435|This message indicates that leaked memory was found that is automatically cleaned up. This scenario can be a consequence of a SAP HANA bug in context of fast data access (FDA).|Block list|including suballocators|
Memory|PoolAllocator.cpp|Destroying allocator 'Connection/<conn_id>/Pool/RowEngine/Session' with <blocks> blocks and <bytes> byte still allocated.|T0312|2580435|This message indicates that leaked memory was found that is automatically cleaned up. This scenario can be a consequence of a SAP HANA bug in context of fast data access (FDA).|Destroying allocator|blocks|byte still allocated
Memory|PoolAllocator.cpp|In-use block ... alloc Pool/RowEngine/Session Block was allocated at ...|T0312|2580435|This message indicates that leaked memory was found that is automatically cleaned up. This scenario can be a consequence of a SAP HANA bug in context of fast data access (FDA).|In-use block|RowEngine|Session Block was allocated at
Memory|PoolAllocator.cpp|Out of memory for <allocator>, size <size>B, alignment=<alignment>B|T0302|1999997|This message indicates which allocator was related to a OOM situation.|Out of memory for|size|alignment
Memory|ptl_shm.cpp|ShmSystem::create (size=<size>) - No space left on device|T0319|1999997|This error is typically a consequence of wrong shared memory settings on OS level. Make sure that parameters like kernel.shmmni, kernel.shmmax and kernel.shmall are set to sufficiently large values. In particular it must be possible to set up and extend shared memory segments for the row store.|ShmSystem|No space left on device|
Memory|ReportMemoryProblems.cpp|Composite limit violation (OUT OF MEMORY) occurred. Composite limit=<limit_byte> Failed to allocate <byte> byte. Top "UnifiedTable" allocators (component, name, size). Ordered descending by inclusive_size_in_use.|T0308|1999997|Statement specific memory limit reached|Composite limit violation|OUT OF MEMORY|Failed to allocate
Memory|ShmAllocator.cpp|shared memory allocation failed: exception  1: no.71000004 ShmSystem::create (size=<size>) - No space left on device|T0319|1999997|This error is typically a consequence of wrong shared memory settings on OS level. Make sure that parameters like kernel.shmmni, kernel.shmmax and kernel.shmall are set to sufficiently large values. In particular it must be possible to set up and extend shared memory segments for the row store.|shared memory allocation failed|ShmSystem|No space left on device
MergeMonitor|TableDeltaMerge.cpp|Invalid auto merge decision function: <wrong_function>, fall back to default: <default_function>|T0820|2057046|This message indicates that the auto_merge_decision_func parameter is set to an invalid value.|Invalid auto merge decision function|fall back to default|
MergeMonitor|TableDeltaMerge.cpp|Smartmerge failed for optimize compression: <schema>:<table> (t <id>), passport=, error: table does not exist|T0825|2057046|This error is written when a smart merge on a non-existing table is triggered. This can be a timing issue that isn't reproducible.|Smartmerge failed for optimize compression|error|table does not exist
Metadata|ToidMapper.cpp|deleteCurrentToidByName: not found toid.|||This error should actually be treated as a warning and not being displayed per default in the database trace. Starting with SAP HANA 1.00.122.11 the trace level is adjusted and this harmless message is no longer displayed.|deleteCurrentToidByName|not found toid|
OMS_VTrace|OMS_VersionDictionary.cpp|OmsVersion max_version_retention time reached, drop now, <id>, createTime=<timestamp>, maxRetentionTimeS=<time_s>|T1410|2593571|This message indicates that the configured version retention time was exceeded (default: 480 minutes): indexserver.ini -> [livecache] -> max_version_retention_time. As a consequence related versions are dropped and subsequent accesses may fail with error "-28514: Version not found".|OmsVersion max_version_retention time reached|drop now|createTime
OOMFlagPropagati|JobExecutorUtil.cp|JobFinalObjectImpl::checkAndThrowException: oom flag transferred||1999997|These messages can appear in context of OOM situations.|JobFinalObjectImpl|checkAndThrowException|oom flag transferred
OOMFlagPropagati|JobExecutorUtil.cp|JobFinalObjectImpl::transferError: oom flag transferred||1999997|These messages can appear in context of OOM situations.|JobFinalObjectImpl|transferError|oom flag transferred
optimize_compres|OptimizeCompressionData.cpp|getDataServer() failed  (table=<schema>:<table> (t <id>), passport=)||2112604|This error is written when the server of a table can't be determined when doing an optimize compressions (e.g. because the table doesn't exist).|getDataServer|failed|table
PersistenceLayer topology|PersistenceController.cpp Topology.cpp|A downward catalog migration from <vers1> to <vers2> is not supported||2380652|Startup prevented due to unsupported catalog downgrade|A downward catalog migration from|is not supported|
PersistenceManag|DisasterRecoveryPrimaryImpl.cpp|New Replication Connection registered for siteId=<site>, index=<index> Address=<ip>/<port>_tcp, host=<host>||1999880|Information message that system replication connection for remote site is registered|New Replication Connection registered for siteId|index|Address
PersistenceManag|DisasterRecoveryProtocol.cpp|Asynchronous replication buffer full, accumulated count = <count>, trace cooldown = <seconds> s|T1210|1999880|This error happens when the asynchronous log shipping buffer in asynchronous system replication environments runs full and it results in a temporary connection close. The behavior can be controlled with buffer size and timeout configuration parameters: global.ini -> [system_replication] -> logshipping_async_wait_on_buffer_full AND <service>.ini -> [system_replication] -> logshipping_async_buffer_size|Asynchronous replication buffer full|accumulated count|trace cooldown
PersistenceManag|DisasterRecoverySecondaryImpl.cpp|Prepare takeover started (operationMode=<operation_mode>)||1999880|System replication takeover initialization. Among others it includes potentially expensive adjustments to resource container dispositions that is only executed in case of operation mode delta_datashipping. With log replay related modes the duration can significantly improve.|Prepare takeover started|operationMode|
PersistenceManag|DisasterRecoverySecondaryImpl.cpp|Prepare takeover finished||1999880|System replication takeover initialization. Among others it includes potentially expensive adjustments to resource container dispositions that is only executed in case of operation mode delta_datashipping. With log replay related modes the duration can significantly improve.|Prepare takeover finished||
PersistenceManag|PersistenceManagerImpl.cpp|BackupChannel: create backup <id> - <id>, redo log position = <pos>||1642148|Creation of a log or data backup|BackupChannel|create backup|redo log position
PersistenceManag|PersistenceManagerImpl.cpp|checking persistence with guid history: guid=<guid>, sp=<sp>, logPos=<log_pos>||1999880|This message indicates a persistence compatibility check that happens when a secondary system replication site connects to the primary site. So it can be an indication for disconnects that happened before.|checking persistence with guid history|guid|logPos
PersistenceManag|PersistenceManagerImpl.cpp|Garbage collection of history files running: <finished> cleanup files of <total> done||2169283|Persistence garbage collection during SAP HANA startup|Garbage collection of history files running|cleanup files of|
PersistenceManag|PersistenceManagerImpl.cpp|Persistency was created with version <version> ...||2100009|Persistence and savepoint detail information, e.g. printed in context of savepoints|Persistency was created with version||
PersistenceManag|PersistenceManagerImpl.cpp|Persistency was last savepointed with version <version> ...||2100009|Persistence and savepoint detail information, e.g. printed in context of savepoints|Persistency was last savepointed with version||
PersistenceManag|PersistenceManagerImpl.cpp|VirtualFile LOB statistics initialized||2222217|Disk LOB (SAP Note 2220627) initialization during startup|VirtualFile LOB statistics initialized||
PersistenceManag|PersistentSpaceImpl.cpp|loadContainerDirectories ... loadContainerDirectories - done.||2400005|Load of container directory entries|loadContainerDirectories||
PersistenceManag|VirtualFileStatsProxy.cpp|LOB owner statistics initialized from VirtualFile: <lob_files> CD entries in <minutes> min||2222217|Disk LOB (SAP Note 2220627) initialization during startup|LOB owner statistics initialized from VirtualFile|CD entries in|
PlanStoreManager|query_plan_store.cc|failed in insert custom plan, what = <error_description>|T1500|2222321|This message is linked to errors when trying to pin SQL plans. The <error_description> is for example "sql syntax error" or "sql processing error".|failed in insert custom plan|what|
PlanViz|qe_table.cc|Uncollected exec stats (pv node is null)||2475609|These errors can show up in context of PlanViz traces, e.g. when a high amount of information is collected for complex execution plans. An optimization is available with SAP HANA >= 1.00.122.10 and >= 2.00.012.|Uncollected exec stats|pv node is null|
pleCompile|ple_command_srv.cpp|Invalidate the session '<session>' due to an exception. node '<node>' could not be created|T0245||This error indicates that a planing engine session was invalidated. You can check accompanying trace file entries for the actual invalidation reason.|Invalidate the session|due to an exception|could not be created
PMRestart|PersistenceSessionRegistry.cpp|Start loading open sessions and history cleanup files||2400005|These trace entries are linked to loading persistence structures during startup. This phase is I/O bound and can take some time in case large amounts of data (e.g. many history files) exist. This phase is only about loading, the actual garbage collection with SAP HANA >= 2.0 happens asynchronously in parallel to production operation.|Start loading open sessions and history cleanup files||
PMRestart|PersistenceSessionRegistry.cpp|UndoFiles: <num>, freeUndoFiles: <num>, CleanupFiles: <num>, CleanupFilesPassedToGC: <num>, lcCleanupFilesPassedToGC: <num>, LC UndoFiles: <num>, LC CleanupFiles: <num>, RemoteOpUndoFiles: <num>||2400005|These trace entries are linked to loading persistence structures during startup. This phase is I/O bound and can take some time in case large amounts of data (e.g. many history files) exist. This phase is only about loading, the actual garbage collection with SAP HANA >= 2.0 happens asynchronously in parallel to production operation.|UndoFiles|freeUndoFiles|CleanupFiles
PMRestart|PersistenceSessionRegistry.cpp|Start loading open sessions and history cleanup files||2400005|These trace entries are linked to loading persistence structures during startup. This phase is I/O bound and can take some time in case large amounts of data (e.g. many history files) exist. This phase is only about loading, the actual garbage collection with SAP HANA >= 2.0 happens asynchronously in parallel to production operation.|Open session count at restart|max known TID at restart|
PMRestart|PersistenceSessionRegistry.cpp|Loading <num> open session(s) and <num> history cleanup file(s) finished in <seconds> seconds||2400005|These trace entries are linked to loading persistence structures during startup. This phase is I/O bound and can take some time in case large amounts of data (e.g. many history files) exist. This phase is only about loading, the actual garbage collection with SAP HANA >= 2.0 happens asynchronously in parallel to production operation.|Loading|open session|history cleanup file
preprocessor|PreprocessorImpl.cpp|Text analysis error '<path>/ISYSConverter.cpp: Line 771: Error 0x05000018: Return code:4, Message:ISYS library failed to process data for unknown reason.', number of errors: 1 HANDLE: DISPATCH - Processing of 1 document(s) failed, last failed document key '<key>'|T0835||These messages indicate errors during text indexing.|ISYS library failed to process data for unknown reason||
QMediator|PlanInfo.cpp|Exception in PtimeInfo: exception 1: no.1000013 (Evaluator/ConvertExpression.cpp:539) not supported function: <function>|||This message indicates that a certain internal performance optimization (e.g. filter transport) isn't possible because the used function isn't supported. This is more an information message than a critical error. Starting with SAP HANA 2.0 SPS 01 this message is considered as warning rather than error.|Exception in PtimeInfo|no.1000013|not supported function
remote_request_e|RemoteRequestExecutor.cpp|OptimizeCompressionData: cannot get data server for '<schema>:<table> (t <id>)'||2112604|This error is written when the server of a table can't be determined when doing an optimize compressions (e.g. because the table doesn't exist).|OptimizeCompressionData|cannot get data server for|
REPOSITORY|activator.cpp|activateObjectsInternalFast2: ActivationID <id>, activation phase: Fatal generate error during generate call of runtime Role runtime.|T1800|2159014|These messages indicate an error during object activation.|activateObjectsInternalFast2|activation phase|Fatal generate error during generate call of runtime Role runtime
REPOSITORY|activator.cpp|Activator::checkAndHandleRollback, activation ID <id>: Commit or rollback in Runtime::generate detected.|T1800|2159014|These messages indicate an error during object activation.|checkAndHandleRollback|Commit or rollback in Runtime|generate detected
REPOSITORY|activator.cpp|activateORepository: Activation failed for at least one objectbjectsInternalFast2: ActivationID <id>, activation phase: Fatal generate error during generate call of runtime Role runtime.|T1800|2159014|These messages indicate an error during object activation.|Repository|Activation failed for at least one object|
REPOSITORY|activator.cpp|Errors were reported by runtime Role runtime ; rolling back transaction|T1800|2159014|These messages indicate an error during object activation.|Errors were reported by runtime Role runtime|rolling back transaction|
REPOSITORY|activator.cpp|Errors were reported by runtime sqlproc-runtime ; rolling back transaction|T1800|2159014|These messages indicate an error during object activation.|Errors were reported by runtime sqlproc-runtime|rolling back transaction|
REPOSITORY|packageStoreAccessor.cpp|Repository: Package not found; "<package>": the package does not exist||2317677|This error indicates that a repository package can't be found.|Repository|Package not found|the package does not exist
ResMan|ResourceContainerShrink.cpp|Information about shrink at <date> <time>|T0310|1999997|Shrink of memory resource container|Information about shrink at||
ResMan|ResourceContainerShrink.cpp|Unloading all resources with release time < <epoch_time>||2127458|This message indicates that resource container unloads with "UNUSED RESOURCE" are triggered because the configured unused retention period (global.ini -> [memoryobjects] -> unused_retention_period) is reached. The <epoch_time> value is a timestamp in epoch time (in micro seconds). You can use www.epochconverter.com to convert it to a normal timestamp.|Unloading all resources with release time||
Row_Engine|LeakedPageList.cc|Disabling container having leaked pages. cid = <id>||2101640|Row store leakage analysis during SAP HANA startup|Disabling container having leaked pages|cid|
Row_Engine|ptime_exception.cc|error in PtimeException construction. see error below.||2222277|This is a general information about an exception in context of row engine processing. Error details (e.g. out of memory) can be found in related trace file lines.|error in PtimeException construction|see error below|
Row_Engine|transdtx.cc|Unexpected ltt exception thrown: transaction distribution work failure|T0558|2399990|This trace entry is typically linked to a termination with error "145: transaction distribution work failure" on client side and can be caused by communication / consistency issues in the SAP HANA server.|Unexpected ltt exception thrown|transaction distribution work failure|
RowStorePageAccess|AbsolutePageAccessImpl.cpp|loadMultiplePageBlocksAtStartup||2222277|Row store initialization and load during SAP HANA startup|loadMultiplePageBlocksAtStartup||
RowStorePageAccess|AbsolutePageAccessImpl.cpp|allocate <segments> segments requested to load and collect information about superblocks to read...||2222277|Row store initialization and load during SAP HANA startup|segments requested to load and collect information about superblocks to read||
RowStorePageAccess|AbsolutePageAccessImpl.cpp|collecting information done in <time_ms>msec.||2222277|Row store initialization and load during SAP HANA startup|collecting information done in|msec|
RowStorePageAccess|AbsolutePageAccessImpl.cpp|trigger load of superblocks done after <time_ms>msec||2222277|Row store initialization and load during SAP HANA startup|trigger load of superblocks done after|msec|
RowStorePageAccess|AbsolutePageAccessImpl.cpp|i/o finished: read <num_superblocks> superblock(s) within <time_ms>ms = <throughput_mc>MB/s overall.||2222277|Row store initialization and load during SAP HANA startup|finished loading all|segments by reading|superblocks after
RS_Container|mm_container.cc|MM: exceed max number (<count>) of containers|T2012|2154870|Check why the maximum number of row store containers was reached and take appropriate actions to avoid this scenario in the future.|MM|exceed max number|of containers
RS_CPBtree|cpb_record_reader_types.cc|Unexpected exception in CP key generation|T0836|2116157|Check for row store corruptions and repair them. Identify the root cause of the corruption and make sure that the problem can no longer happen in the future.|Unexpected exception in CP key generation||
RS_CPBtree|cpb_tree.cc|Giving up to collect stat of CPB+-tree index||2222277|This message indicates that the creation of row store index statistics (e.g. in context of accesses to monitoring views like M_RS_INDEXES) is terminated prematurely. This can happen for different reasons, e.g. if concurrent changes happen or if many row store versions exist. This message isn't critical, the underlying query succeeds and isn't terminated. As a side-effect of the termination some row store index statistics (e.g. index size or entry count) can be inaccurate.|Giving up to collect stat of CPB+-tree index||
RS_IndexLoad|IndexManager_load.cc|Error in parsing cpkey during RS index build|T0441|2116157|Check for row store corruptions and repair them. Identify the root cause of the corruption and make sure that the problem can no longer happen in the future.|Error in parsing cpkey during RS index build||
RS_IndexLoad|IndexManager_load.cc|external reference in v-slot corrupted: record_ID = <record_id>|T0441|2116157|Check for row store corruptions and repair them. Identify the root cause of the corruption and make sure that the problem can no longer happen in the future.|external reference in v-slot corrupted|record_ID|
RS_IndexLoad|IndexManager_load.cc|table content corruption identified during RS index build: schema = "<schema>", table = "<table>", index = "<index>"|T0441|2116157|Check for row store corruptions and repair them. Identify the root cause of the corruption and make sure that the problem can no longer happen in the future.|table content corruption identified during RS index build||
RS_IndexLoad|IndexManager_load.cc|unexpected external reference in v-slot|T0441|2116157|Check for row store corruptions and repair them. Identify the root cause of the corruption and make sure that the problem can no longer happen in the future.|unexpected external reference in v-slot||
RS_IndexLoad|IndexManager_load.cc|unexpected table content identified during RS index build|T0441|2116157|Check for row store corruptions and repair them. Identify the root cause of the corruption and make sure that the problem can no longer happen in the future.|unexpected table content identified during RS index build||
RS_TableManager|Var.cc|invalid v-slot pointer (wrong page header) identified during variable-size field traversal: storage_type = <type>, v-slot = <vslot>|T0442|2116157|Check for row store corruptions and repair them. Identify the root cause of the corruption and make sure that the problem can no longer happen in the future.|invalid v-slot pointer|wrong page header|identified during variable-size field traversal
RS_TableManager|Var.cc|slot sanity check failure|T0442|2116157|Check for row store corruptions and repair them. Identify the root cause of the corruption and make sure that the problem can no longer happen in the future.|slot sanity check failure||
RS_TableManager|VarGroupBase.cc|An invalid encoded character detected  value=<value>|T0443|2116157|Check for row store corruptions and repair them. Identify the root cause of the corruption and make sure that the problem can no longer happen in the future.|An invalid encoded character detected|value|
RS_Version_GC|LinkVersion_collect.cc|exception @ LinkVersion::executionPostDDLAction(), DELETE, getFullMessage()=attempt to access metadata of an invalid address (already deleted or corrupted, etc.)|T0840|2581110|This message is caused by a SAP HANA bug in context of the xsengine.|executionPostDDLAction|attempt to access metadata of an invalid address|already deleted or corrupted
RsGarbageLobs|garbage_lob_file_handler.cc|failed to remove RS lob garbage file : no server was found for $VOLUMEID$|T0841|2351467|Proceed according to SAP Note 2351467 and consider an upgrade to SAP HANA >= 1.00.122.02.|failed to remove RS lob garbage file|no server was found for|
Savepoint|SavepointImpl.cpp|Clearing backup Snapshot Restart page number from the Anchor page||2100009|Drop of a backup related SAP HANA snapshot|Clearing backup Snapshot Restart page number from the Anchor page||
Savepoint|SavepointImpl.cpp|NOTE: BACKUP DATA needed to ensure recoverability of the database ... Starting initial BACKUP DATA, recoverability of the database will be ensured afterwards|T1015|1642148 2100009|The first message indicates that due to an absence of a data backup the recoverability of the SAP HANA database isn't guaranteed and a data backup needs to be taken. The second message indicates that an initial data backup is started.|BACKUP DATA needed to ensure recoverability of the database||
Savepoint|SavepointImpl.cpp|NOTE: BACKUP DATA needed to ensure recoverability of the database ... Starting initial BACKUP DATA, recoverability of the database will be ensured afterwards|T1015|1642148 2100009|The first message indicates that due to an absence of a data backup the recoverability of the SAP HANA database isn't guaranteed and a data backup needs to be taken. The second message indicates that an initial data backup is started.|Starting initial BACKUP DATA|recoverability of the database will be ensured afterwards|
SERVER_TRACE|DeltaIndexManager.cpp|docIdSearch failed for main index with rc=<rc>||2163068 2361364|This error indicates a problem when accessing doc IDs in main or delta. The actual root cause depends on the return code, e.g.: rc=6931: problems when parsing a data value (SAP Note 2361364) AND rc=6944: overflow in numeric calculation (e.g. SAP Note 2163068)|docIdSearch failed for main index with rc||
SERVER_TRACE|DeltaIndexManager.cpp|docIdSearch failed for main index with rc=<rc>||2163068 2361364|This error indicates a problem when accessing doc IDs in main or delta. The actual root cause depends on the return code, e.g.: rc=6931: problems when parsing a data value (SAP Note 2361364) AND rc=6944: overflow in numeric calculation (e.g. SAP Note 2163068)|docIdSearch failed for delta index with rc||
SERVER_TRACE|DeltaIndexManager.cpp|mergeDeltaIndex failed for <schema>:<table> (<id>) rc=2450|T0830|1860493|Delta merge termination due to OOM|mergeDeltaIndex failed for|rc=2450|
Service|TrexService.c|FATAL: initialization of service failed with exception exception 1: no.7100007 Error while resolving groupname rc=2: No such file or directory||2670327|This error indicates a problem with the operating system groups assigned to the <sid>adm use|FATAL|initialization of service failed with exception exception|No such file or directory
Service_Shutdown|tcp_listener.cpp|stop the SQL listening port: <port>||2177064|Stop of SQL listener port during service shutdown|stop the SQL listening port||
Service_Shutdown|tcp_listener.h|Shutdown SqlListener service||2177064|Shutdown of SQL listener during service shutdown|Shutdown SqlListener service||
Service_Shutdown|TREXIndexServer.cpp|Triggering timezone checker shutdown||2177064|Shutdown of various components during service shutdown|Triggering timezone checker shutdown||
Service_Shutdown|TREXIndexServer.cpp|unassign from volume <volume_id>||2177064|Shutdown of various components during service shutdown|unassign from volume||
Service_Shutdown|TREXIndexServer.cpp|Preparing to shutdown||2177064|Shutdown of various components during service shutdown|Preparing to shutdown||
Service_Shutdown|TREXIndexServer.cpp|stopping statistics server worker threads||2177064|Shutdown of various components during service shutdown|stopping statistics server worker threads||
Service_Shutdown|TREXIndexServer.cpp|stopping dynamic range partitioning||2177064|Shutdown of various components during service shutdown|stopping dynamic range partitioning||
Service_Shutdown|TREXIndexServer.cpp|stopping federation statistics collection||2177064|Shutdown of various components during service shutdown|stopping federation statistics collection||
Service_Shutdown|TREXIndexServer.cpp|stopping extended storage heartbeat thread||2177064|Shutdown of various components during service shutdown|stopping extended storage heartbeat thread||
Service_Shutdown|TREXIndexServer.cpp|Abort logreplay||2177064|Shutdown of various components during service shutdown|Abort logreplay||
Service_Shutdown|TREXIndexServer.cpp|Stopping LOBGarbageCollectorThread||2177064|Shutdown of various components during service shutdown|Stopping LOBGarbageCollectorThread||
Service_Shutdown|TREXIndexServer.cpp|Stopping EPM||2177064|Shutdown of various components during service shutdown|Stopping EPM||
Service_Shutdown|TREXIndexServer.cpp|Stopping Embedded Catalyst Services||2177064|Shutdown of various components during service shutdown|Stopping Embedded Catalyst Services||
Service_Shutdown|TREXIndexServer.cpp|Stopping PlanningEngine||2177064|Shutdown of various components during service shutdown|Stopping PlanningEngine||
Service_Shutdown|TREXIndexServer.cpp|Stopping SQL session service||2177064|Shutdown of various components during service shutdown|Stopping SQL session service||
Service_Shutdown|TREXIndexServer.cpp|Stopping SQL plan cache||2177064|Shutdown of various components during service shutdown|Stopping SQL plan cache||
Service_Shutdown|TREXIndexServer.cpp|Stopping QueueServer...||2177064|Shutdown of various components during service shutdown|Stopping QueueServer||
Service_Shutdown|TREXIndexServer.cpp|Stopping PlanViz||2177064|Shutdown of various components during service shutdown|Stopping PlanViz||
Service_Shutdown|TREXIndexServer.cpp|Stopping TRexApiSystem||2177064|Shutdown of various components during service shutdown|Stopping TRexApiSystem||
Service_Shutdown|TREXIndexServer.cpp|Stopping executor||2177064|Shutdown of various components during service shutdown|Stopping executor||
Service_Shutdown|TREXIndexServer.cpp|Stopping DebuggingBackend||2177064|Shutdown of various components during service shutdown|Stopping DebuggingBackend||
Service_Shutdown|TREXIndexServer.cpp|Stopping CalculationEngineManager||2177064|Shutdown of various components during service shutdown|Stopping CalculationEngineManager||
Service_Shutdown|TREXIndexServer.cpp|Stopping TaskManager||2177064|Shutdown of various components during service shutdown|Stopping TaskManager||
Service_Shutdown|TREXIndexServer.cpp|Stopping TaskStatisticsManager||2177064|Shutdown of various components during service shutdown|Stopping TaskStatisticsManager||
Service_Shutdown|TREXIndexServer.cpp|Stopping CacheMgr||2177064|Shutdown of various components during service shutdown|Stopping CacheMgr||
Service_Shutdown|TREXIndexServer.cpp|Stopping GraphEngineMgr||2177064|Shutdown of various components during service shutdown|Stopping GraphEngineMgr||
Service_Shutdown|TREXIndexServer.cpp|Stopping Invalidator||2177064|Shutdown of various components during service shutdown|Stopping Invalidator||
Service_Shutdown|TREXIndexServer.cpp|Stopping RClient||2177064|Shutdown of various components during service shutdown|Stopping RClient||
Service_Shutdown|TREXIndexServer.cpp|Stopping SAMLFactory||2177064|Shutdown of various components during service shutdown|Stopping SAMLFactory||
Service_Shutdown|TREXIndexServer.cpp|Stopping JWTFactory||2177064|Shutdown of various components during service shutdown|Stopping JWTFactory||
Service_Shutdown|TREXIndexServer.cpp|Stopping VSI runtime||2177064|Shutdown of various components during service shutdown|Stopping VSI runtime||
Service_Shutdown|TREXIndexServer.cpp|Unassigning all tables||2177064|Shutdown of various components during service shutdown|Unassigning all tables||
Service_Shutdown|TREXIndexServer.cpp|Starting unloading of 43752 tables with 64 parallel threads (683 tables per thread)||2177064|Shutdown of various components during service shutdown|Starting unloading of 43752 tables with 64 parallel threads|tables per thread|
Service_Shutdown|TrexService.cpp|Preparing for shutting service down||2177064|Service shutdown|Preparing for shutting service down||
Service_Startup|DataPageRelinkList.cc|Found leaked page, pageid=<id>, cid=<id>, parent_cid=<id>||2101640|Row store leakage analysis during SAP HANA startup|Found leaked page|pageid|parent_cid
Service_Startup|GlobalTransCommImpl.cpp|Finished processing Slave_GetMasterLogPos, lsn=<id>||2222217|These messages can be written during restart on a regular basis, but they are no issue themselves. Instead they indicate that the SAP HANA startup is delayed for other reasons, e.g. rollback or persistence garbage collection.|Finished processing Slave_GetMasterLogPos||
Service_Startup|GlobalTransCommImpl.cpp|Processing Slave_GetMasterLogPos for volume <id>||2222217|These messages can be written during restart on a regular basis, but they are no issue themselves. Instead they indicate that the SAP HANA startup is delayed for other reasons, e.g. rollback or persistence garbage collection.|Processing Slave_GetMasterLogPos for volume||
Service_Startup|IndexManager_load.cc|duplicate records found during index rebuild. index name: <index>, table name: <schema>:<table>|T0445|2116157|Check for row store corruptions and repair them. Identify the root cause of the corruption and make sure that the problem can no longer happen in the future.|duplicate records found during index rebuild|ndex name|table name
Service_Startup|IntegrityChecker.cc|Checking rowstore consistency.|T0444|2116157 2222217|Row store consistency check during SAP HANA startup|Checking rowstore consistency||
Service_Startup|IntegrityChecker.cc|Checking rowstore consistency.|T0444|2116157 2222217|Row store consistency check during SAP HANA startup|inconsistencies from consistency check|please execute the procedure|CHECK_TABLE_CONSISTENCY
Service_Startup|mm_recovery.cc|[RSReorg] start||1813245|Offline row store reorganization|RSReorg|start|
Service_Startup|mm_recovery.cc|[RSReorg] success (<pages> pages)||1813245|Offline row store reorganization|RSReorg|success|pages
Service_Startup|mm_recovery.cc|[RSReorg] finished in <seconds> sec||1813245|Offline row store reorganization|RSReorg|finished in|sec
Service_Startup|PageRelocator.cc|[RSReorg] Phase 1/13. check catalog integrity||1813245|Offline row store reorganization|RSReorg|check catalog integrity|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 1/13. checked catalog integrity successfully in <seconds> sec||1813245|Offline row store reorganization|RSReorg|checked catalog integrity successfully in|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 2/13. collect target pages||1813245|Offline row store reorganization|RSReorg|collect target pages|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 2/13. collected <pages> pages in <seconds> sec||1813245|Offline row store reorganization|RSReorg|collected|pages in
Service_Startup|PageRelocator.cc|[RSReorg] estimated log space required: <log_mb> MB, free disk space for redo log partition: <disk_mb> MB, available heap memory for undo log: <undo_mb> MB||1813245|Offline row store reorganization|RSReorg|estimated log space required|free disk space for redo log partition
Service_Startup|PageRelocator.cc|[RSReorg] Phase 3/13. check if version exists||1813245|Offline row store reorganization|RSReorg|check if version exists|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 3/13. checked if version exists in <seconds> sec||1813245|Offline row store reorganization|RSReorg|checked if version exists in|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 4/13. gather all pointer types||1813245|Offline row store reorganization|RSReorg|gather all pointer types|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 4/13. gathered all pointer types in <seconds> sec||1813245|Offline row store reorganization|RSReorg|gathered all pointer types in|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 5/13. build pointer map||1813245|Offline row store reorganization|RSReorg|build pointer map|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 5/13. built pointers map in <seconds> sec||1813245|Offline row store reorganization|RSReorg|built pointers map in|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 6/13. compute checksum of user tables||1813245|Offline row store reorganization|RSReorg|compute checksum of user tables|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 6/13. tables sorted in order by number of pages||1813245|Offline row store reorganization|RSReorg|tables sorted in order by number of pages|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 6/13. user table page checksum calculated||1813245|Offline row store reorganization|RSReorg|user table page checksum calculated|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 6/13. user table cardinality collected||1813245|Offline row store reorganization|RSReorg|user table cardinality collected|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 6/13. compute checksum of variable pages||1813245|Offline row store reorganization|RSReorg|compute checksum of variable pages|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 6/13. ETA <seconds> sec||1813245|Offline row store reorganization|RSReorg|ETA|sec
Service_Startup|PageRelocator.cc|[RSReorg] Phase 6/13. processing <pct>%||1813245|Offline row store reorganization|RSReorg|processing|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 6/13. variable page checksum calculated||1813245|Offline row store reorganization|RSReorg|variable page checksum calculated|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 6/13. computed checksum of user table contents and variable-length data in <seconds> sec||1813245|Offline row store reorganization|RSReorg|computed checksum of user table contents and variable-length data in <seconds> sec|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 7/13. compute checksum of metadata||1813245|Offline row store reorganization|RSReorg|compute checksum of metadata|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 7/13. computed checksum of metadata in <seconds> sec||1813245|Offline row store reorganization|RSReorg|computed checksum of metadata in|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 8/13. move pages||1813245|Offline row store reorganization|RSReorg|move pages|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 8/13. moved <pages> pages in <seconds> sec||1813245|Offline row store reorganization|RSReorg|moved|pages in
Service_Startup|PageRelocator.cc|[RSReorg] Phase 9/13. update pointer references||1813245|Offline row store reorganization|RSReorg|update pointer references|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 9/13. updated pointer references in <seconds> sec||1813245|Offline row store reorganization|RSReorg|updated pointer references in|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 10/13. check catalog integrity||1813245|Offline row store reorganization|RSReorg|check catalog integrity|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 10/13. checked catalog integrity successfully in <seconds> sec||1813245|Offline row store reorganization|RSReorg|checked catalog integrity successfully in|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 11/13. compare variable-length data checksum||1813245|Offline row store reorganization|RSReorg|compare variable-length data checksum|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 11/13. compared variable-length data checksum in <seconds> sec||1813245|Offline row store reorganization|RSReorg|compared variable-length data checksum in|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 12/13. compare user table contents checksum||1813245|Offline row store reorganization|RSReorg|compare user table contents checksum|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 12/13. tables sorted in order by number of pages||1813245|Offline row store reorganization|RSReorg|tables sorted in order by number of pages|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 12/13. user table page checksum calculated||1813245|Offline row store reorganization|RSReorg|user table page checksum calculated|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 12/13. compared user table contents checksum in <seconds> sec||1813245|Offline row store reorganization|RSReorg|compared user table contents checksum in|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 13/13. free target pages||1813245|Offline row store reorganization|RSReorg|free target pages|
Service_Startup|PageRelocator.cc|[RSReorg] Phase 13/13. freed target pages in <seconds> sec||1813245|Offline row store reorganization|RSReorg|freed target pages in|
Service_Startup|PageRelocator.cc|[RSReorg] RowStore memory reduced from <mem_source_mb> MB (<source_seg> segments) to <mem_target_mb> MB (<target_seg> segments) by moving <pages> pages.||1813245|Offline row store reorganization|RSReorg|RowStore memory reduced from|by moving
Service_Startup|PageRelocator.cc|[RSReorg] make sure that free segments are deallocated||1813245|Offline row store reorganization|RSReorg|make sure that free segments are deallocated|
Service_Startup|PageRelocator.cc|[RSReorg] trigger asynchronous savepoint||1813245|Offline row store reorganization|RSReorg|trigger asynchronous savepoint|
Service_Startup|SmFastRestart.cc|Loading RowStore segments from Persistency||2222217|Load of row store pages into memory during SAP HANA startup|Loading RowStore segments from Persistency||
Service_Startup|TREXIndexServer.cpp|Pre-/Re-Loading of column store tables finished.||2127458|Information that load of tables into column store is finished|Re-Loading of column store tables finished||
Service_Shutdown|TrexService.cpp|Preparing for shutting service down||2177064|Service shutdown|Preparing for shutting service down||
SessionContextCa|SessionContext.cc|no connection on volume<volume>|T0630|2287190|There is a problem accessing a volume on a remote node / service (e.g. network issues, timeouts).|no connection on volume||
SessionRemoteReq|SessionContextRequestHandler.cc|failed to handle disconnect related connections request: session context error: no such session context||2092196|This error is a consequence of a no longer existing session context (e.g. due to cancellation, disconnect or timeouts)|failed to handle disconnect related connections request|session context error|no such session context
SessionRemoteReq|SessionRequestHandler.cc|failed to retrieve local session context ... [session request handler] unhandled exception: session context error: no such session context||2092196 2287190|These error is a consequence of a no longer existing session context (e.g. due to cancellation, disconnect, network issues or timeouts)|failed to retrieve local session context||
SessionRemoteReq|SessionRequestHandler.cc|failed to retrieve local session context ... [session request handler] unhandled exception: session context error: no such session context||2092196 2287190|These error is a consequence of a no longer existing session context (e.g. due to cancellation, disconnect, network issues or timeouts)|session request handler|unhandled exception|session context error
SLDCollect|CIMModel.cpp|SAP_IdenticalDatabaseSystem relation without systemdb logical database hostname configured: skip memberclass|||This message indicates an inappropriate configuration of a virtual database in SLD environments, e.g. a virtdbhome configuration for only some tenants in a multitenant environment. Check the SAP HANA Administration Guide ("Configuring SAP HANA for System Replication Technical Scenario in SAP Solution Manager") for more details.|SAP_IdenticalDatabaseSystem relation without systemdb logical database hostname configured|skip memberclass|
SLDCollect|CRContent.cpp|Product '<product>' from vendor '<vendor>' with version '<version>' and ppms_id '<ppms_id>' and sid <sid>' misses key properties and will not be reported||669669|In general this error is rather harmless and only indicates that product data isn't propagated to Solution Manager and so product details like versions aren't available. Check why the mentioned product has missing key properties for SLD and correct it. If it is not a SAP product, get in touch with the 3rd party vendor, otherwise you can open a SAP incident on component HAN-LM-PLT.|misses key properties and will not be reported|ppms_id|from vendor
SLDSend|Sld.cpp|Error executing "sldreg -connectfile /usr/sap/<sid>/SYS/global/slddest.cfg -file /usr/sap/<sid>/HDB<inst_id>/<host>/trace/sldreg.xml -log|T1600||This error indicates a problem while executing the System Landscape Directory registration (sldreg) command. You can check accompanying trace mesages for error details. For example, the following error indicates an issue with memory alocation ("Cannot allocate memory") that can be analyzed based on SAP Note 1999997: Cannot spawn child process "sldreg" "-connectfile" "slddest.cfg" "-file" AND "sldreg.xml" "-logfile" "sldreg.log": 12 (Cannot allocate memory)|Error executing|sldreg|connectfile
SLDSend|Sld.cpp|SldReg config file missing: /usr/sap/<sid>/SYS/global/slddest.cfg|T1605|2533657|This error indicates that the System Landscape Directory (SLD) configuration file is missing.|SldReg config file missing||
SqlOpt_qe_gen|qo_gen_exec_plan_rel.cc|Error message : fatal error: ColDicVal (<id>, <id>) not found|T0246|2681828|This is an internal error during parsing, that can e.g. be caused by the SAP HANA bug described in SAP Note 2681828. In other scenarios a sqloptstep trace can help to identify error details.|Error message|fatal error|ColDicVal
SQLQuery|qe_itab_materializer.cc|Insert into column[<id>] failed Num fetch thread: <id> Slave buf : <id> Operator details: M_SERVICE_THREAD_SAMPLES.HOST ...|T0110|2570661|This error indicates that an error happened during an INSERT operation, e.g. due to a SAP HANA bug when historicizing M_SERVICE_THREAD_SAMPLES.|Insert into column|failed Num fetch thread|M_SERVICE_THREAD_SAMPLES.HOST
SQLScriptCompile|so_qp2so.cc|Inconsistency found between Metadata and Object Dependency Table! DBID: 0, OID: <object_id>, Object Type: <type_1> (Metadata), <type_2> (Object Dependency Table)||2498587|False alert of metadata inconsistency related to object type|Inconsistency found between Metadata and Object Dependency Table|Object Dependency Table|
SQLScriptExecuto|se_eapi_proxy.cc|Error <exception 71000 ... in execution of internal statement: ... _SYS_STATISTICS ...|T0100|2147247|These trace entries are a consequences of internal SAP HANA statistics server errors (e.g. SAP Note 2570661). See SAP Note 2147247 ("How can internal statistics server errors be analyzed?") for more details on how to analyze internal statistics server errors.|exception 71000|in execution of internal statement|_SYS_STATISTICS
SQLScriptExecuto|se_eapi_proxy.cc|Error <exception 71000139: Canceled operator||2092196|This error is a consequence of a cancellation, e.g. due to the end user or a timeout.|exception 71000139|Canceled operator|Error
SQLScriptExecuto|se_eapi_proxy.cc|Error <exception 71000139: ptime::PtimeException||2092196|Termination due to ptime exception, e.g. due to a cancellation|exception 71000139|PtimeException|Error
SQLSession|cm_tcp_channel.cc|cannot close a stream socket: associated object=<id>, error: exception  1: no.71000005|T0560|2385992|This error can be linked to the SSL connection issue described in SAP Note 2385992 or it can be caused by infrastructure issues in the network area (SAP Note 2222200).|cannot close a stream socket|associated object|no.71000005
SQLSession|cm_tcp_channel.cc|NO exception throw location recorded. Stack generation suppressed.||2313619|This message indicates that no call stack was recorded in an error situation.|NO exception throw location recorded|Stack generation suppressed|
SQLSession|sm_codec_newdb.cc|Cancel was requested while reading LOB. The current transaction is aborted||2092196|This error is written when a transaction is aborted (e.g. due to an explicit cancel or a timeout) while a LOB value is read.|Cancel was requested while reading LOB|The current transaction is aborted|
SQLSession|sm_codec_newdb.cc|failed to encode cursor: feature not supported|T0218|1969700|This trace entry is a consequence of using unsupported features, the client typically receives a "7: feature not supported" termination message.|failed to encode cursor|feature not supported|
SQLSession|sm_codec_newdb.cc|unknown statement id (<action>): <statement_id>|||This message is printed when a client tries to release a cursor that doesn't exist. It can for example happen when a cursor is implicitly closed and the client later on tries to close it again.|unknown statement id||
SQLSession|sm_handler.cc|END OF SESSION DUMP|||Detailed connection information in case a session ran into an error|END OF SESSION DUMP|ACTION|CHANNEL
SQLSession|sm_handler.cc|START OF SESSION DUM|||Detailed connection information in case a session ran into an error|START OF SESSION DUM|ACTION|CHANNEL
SQLSession|sm_handler.cc|(sockfd:<id>, part:<id>, channel:<id>, event:<id>) was closed because of invalid packet length||2222200|This error indicates a wrong network package size that can be caused by both infrastructure issues or problems on the remote system / service.|was closed because of invalid packet length|sockfd|channel
SQLSession|sm_handler.cc|session was forcibly closed by the remote host||2621115|This error indicates that a client closes a connection before it is completely established.|session was forcibly closed by the remote host||
SQLSession|sm_handler.cc|(sockfd:<id>, part:<id>, channel:0x<id>, event:0x<id>) was closed because consecutive requests detected (current state:<id>)||2092196|This error indicates that a request was terminated because a new request was sent on the same connection. This can e.g. be cause by a rollback request related to a cancellation (e.g. by user oder timeout).|was closed because consecutive requests detected|current state|sockfd
SQLSession|sm_handler.cc|SSL initialization or handshake error: cannot establish session because the initial communication timeout was reached: timeout=<timeout_ms>||2385992|This timeout can be a consequence of throughput issues when processing SSL connection requests.|SSL initialization or handshake error|cannot establish session because the initial communication timeout was reached|
SQLSession|sm_manager.cc|(get channel) different gcid: gcid=<id>, acquired gcid=<id> sockfd=<id>||2092196|This error can be a consequence of a session termination (e.g. due to manual cancel or timeout)|get channel|different gcid|acquired gcid
SQLSession|sm_session.cc|ERROR [SQL-600] failed routed execution: no activated external transaction||2591281|This termination can be a consequence of a JDBC bug that is fixed with SAP HANA >= 1.00.122.16, >= 2.00.12.05 and >= 2.00.024.|ERROR|SQL-600|no activated external transaction
SQLSession|sm_session.cc|maximum number of external connections (65536) exceeded|T2011|2154870|This error is generated if the limit of configured external connections is reached.|maximum number of external connections|exceeded|
SQLSession|tcp_listener.cc|SqlListener failed to handle event: ERROR [CODE-142] exceed max num of concurrent transactions: maximum number of external connections exceeded||2154870|This error is generated if the limit of configured external connections is reached.|SqlListener failed to handle event|ERROR|CODE-142
SQLSessionCmd|Connection.cc|cancel requested for <conn_id>||2092196|This message indicates that a termination request (e.g. CANCEL SESSION, DISCONNECT SESSION) was executed for a connection.|cancel requested for||
SQLSessionCmd|Statement.cc|INI configuration is changed by <conn_id>, client ip=<ip>, client port=<port>, query=ALTER SYSTEM ALTER CONFIGURATION ...||2186744|Adjustment of SAP HANA parameter settings|INI configuration is changed by|client ip|query
SQLSessionCmd|Statement.cc|plan cache control command is performed by <conn_id>, client ip=<ip>, client port=port, query=<query>||2124112|Explicit SQL cache adjustments (e.g. RECOMPILE, CLEAR)|plan cache control command is performed by|client ip|query
SQLSessionCmd|Statement.cc|session control command is performed by <conn_id>, client ip=<ip>, client port=<port>, query=<query>||2092196|This message indicates that a specific session control command (e.g. <query> = ALTER SYSTEM CANCEL SESSION '320545') was executed.|session control command is performed by|client ip|query
SQLSessionCmd|tcp_listener.cc|canceled session still not finished (cancellation might be still on-going)|T0845|2092196|This message indicates that a CANCEL request was started, but so far it wasn't successful (e.g. because of a long rollback or because the related activity hasn't listened for the CANCEL request, yet.|canceled session still not finished|cancellation might be still on-going|
SQLSessionCmd|tcp_listener.cc|canceled transaction still not finished (cancelation might be still on-going)|T0845|2092196|This message indicates that a CANCEL request was started, but so far it wasn't successful (e.g. because of a long rollback or because the related activity hasn't listened for the CANCEL request, yet.|canceled transaction still not finished|cancelation might be still on-going|
sr_dataaccess|DisasterRecoveryPrimaryImpl.cpp|Closing connection to siteID <site_id>. LogShipping was waiting for <seconds> seconds (logshipping_timeout = <timeout_s>)|T1205|1999880|System replication log shipping timeout|Closing connection to siteID|LogShipping was waiting for|seconds
sr_dataaccess|DisasterRecoveryProtocol.cpp|error=exception 3000321: Asynchronous Replication Buffer is Overloaded|T1210|1999880|This error happens when the asynchronous log shipping buffer in asynchronous system replication environments runs full and it results in a temporary connection close. The behavior can be controlled with buffer size and timeout configuration parameters: global.ini -> [system_replication] -> logshipping_async_wait_on_buffer_full AND <service>.ini -> [system_replication] -> logshipping_async_buffer_size|exception 3000321|Asynchronous Replication Buffer is Overloaded|error
sr_dataaccess|DisasterRecoverySecondaryImpl.cpp|Trying to reconnect to primary ... Error occurred during connect to primary: exception 3000301: Connection could not be established||1999880|This error indicates that the secondary system replication site can't reach the primary site.|Error occurred during connect to primary|exception 3000301|Connection could not be established
sr_dataaccess|PersistenceManagerImpl.cpp|Trying to reconnect for compat check to primary ... Error occurred during connect for compat check with primary: exception ...||1999880|These messages indicate that a secondary / tertiary system replication site isn't able to check the compatibility of the primary site and so system replication can't be established. Different reasons can result in exceptions, e.g.: ... see note 2380176 and 1999880 ... Analyze the reported error and eliminate the root cause. Check if you really want to establish system replication. If not and you instead want to start up the secondary / tertiary site as new primary, you have to perform a takeover of unregister the site before starting.|Error occurred during connect for compat check with primary|exception|
sr_dataaccess|PersistenceManagerImpl.cpp|exception 300010: Cannot create SSL context||1999880|These messages indicate that a secondary / tertiary system replication site isn't able to check the compatibility of the primary site and so system replication can't be established. Different reasons can result in exceptions, e.g.: ... see note 2380176 and 1999880 ... Analyze the reported error and eliminate the root cause. Check if you really want to establish system replication. If not and you instead want to start up the secondary / tertiary site as new primary, you have to perform a takeover of unregister the site before starting.|exception 300010|Cannot create SSL context|
sr_dataaccess|PersistenceManagerImpl.cpp|exception 2000036: Invalid size 0 requested||1999880|These messages indicate that a secondary / tertiary system replication site isn't able to check the compatibility of the primary site and so system replication can't be established. Different reasons can result in exceptions, e.g.: ... see note 2380176 and 1999880 ... Analyze the reported error and eliminate the root cause. Check if you really want to establish system replication. If not and you instead want to start up the secondary / tertiary site as new primary, you have to perform a takeover of unregister the site before starting.|exception 2000036|Invalid size 0 requested|
sr_dataaccess|PersistenceManagerImpl.cpp|exception 2110004: Error invalid address: getaddrinfo, rc=-2: Name or service not known||1999880|These messages indicate that a secondary / tertiary system replication site isn't able to check the compatibility of the primary site and so system replication can't be established. Different reasons can result in exceptions, e.g.: ... see note 2380176 and 1999880 ... Analyze the reported error and eliminate the root cause. Check if you really want to establish system replication. If not and you instead want to start up the secondary / tertiary site as new primary, you have to perform a takeover of unregister the site before starting.|exception 2110004|Error invalid address|Name or service not known
sr_dataaccess|PersistenceManagerImpl.cpp|exception 2110004: Error invalid address: getaddrinfo, rc=-3:Temporary failure in name resolution||1999880|These messages indicate that a secondary / tertiary system replication site isn't able to check the compatibility of the primary site and so system replication can't be established. Different reasons can result in exceptions, e.g.: ... see note 2380176 and 1999880 ... Analyze the reported error and eliminate the root cause. Check if you really want to establish system replication. If not and you instead want to start up the secondary / tertiary site as new primary, you have to perform a takeover of unregister the site before starting.|exception 2110004|Error invalid address|Temporary failure in name resolution
sr_dataaccess|PersistenceManagerImpl.cpp|exception 3000301: Connection could not be established||1999880|These messages indicate that a secondary / tertiary system replication site isn't able to check the compatibility of the primary site and so system replication can't be established. Different reasons can result in exceptions, e.g.: ... see note 2380176 and 1999880 ... Analyze the reported error and eliminate the root cause. Check if you really want to establish system replication. If not and you instead want to start up the secondary / tertiary site as new primary, you have to perform a takeover of unregister the site before starting.|exception 3000301|Connection could not be established|
sr_dataaccess|PersistenceManagerImpl.cpp|exception 3000302: Backup has not yet been executed on primary system! Please backup primary system.||1999880|These messages indicate that a secondary / tertiary system replication site isn't able to check the compatibility of the primary site and so system replication can't be established. Different reasons can result in exceptions, e.g.: ... see note 2380176 and 1999880 ... Analyze the reported error and eliminate the root cause. Check if you really want to establish system replication. If not and you instead want to start up the secondary / tertiary site as new primary, you have to perform a takeover of unregister the site before starting.|exception 3000302|Backup has not yet been executed on primary system! Please backup primary system|
sr_dataaccess|PersistenceManagerImpl.cpp|exception 3000303: Primary is not in log mode normal||1999880|These messages indicate that a secondary / tertiary system replication site isn't able to check the compatibility of the primary site and so system replication can't be established. Different reasons can result in exceptions, e.g.: ... see note 2380176 and 1999880 ... Analyze the reported error and eliminate the root cause. Check if you really want to establish system replication. If not and you instead want to start up the secondary / tertiary site as new primary, you have to perform a takeover of unregister the site before starting.|exception 3000303|Primary is not in log mode normal|
sr_dataaccess|PersistenceManagerImpl.cpp|exception 3000327: Invalid Connection||1999880|These messages indicate that a secondary / tertiary system replication site isn't able to check the compatibility of the primary site and so system replication can't be established. Different reasons can result in exceptions, e.g.: ... see note 2380176 and 1999880 ... Analyze the reported error and eliminate the root cause. Check if you really want to establish system replication. If not and you instead want to start up the secondary / tertiary site as new primary, you have to perform a takeover of unregister the site before starting.|exception 3000327|Invalid Connection|
sr_dataaccess|PersistenceManagerImpl.cpp|exception 3040051: Error reading segment directory||1999880|These messages indicate that a secondary / tertiary system replication site isn't able to check the compatibility of the primary site and so system replication can't be established. Different reasons can result in exceptions, e.g.: ... see note 2380176 and 1999880 ... Analyze the reported error and eliminate the root cause. Check if you really want to establish system replication. If not and you instead want to start up the secondary / tertiary site as new primary, you have to perform a takeover of unregister the site before starting.|exception 3040051|Error reading segment directory|
sr_nameserver|DRClient.cpp|resolveHost <host> not found in global.ini/[system_replication_hostname_resolution]||1999880|This error is reported when an internal system replication host name resolution is configured (global.ini -> [system_replication_communication] -> listeninterface = .internal) but no proper internal mapping exists in section global.ini -> [system_replication_hostname_resolution]. Either disable the internal mapping or configure proper mappings.|resolveHost|not found in global.ini|
sr_nameserver|DRClientUtils.cpp|Read phase '<id>' from takeover file: <file>||1999880|This message is printed while processing a system replication takeover.|Read phase|from takeover file|
sr_nameserver|DRRequestHandler.cpp|drGetServers: incompatible version from dc=1(<version>) but expected (<version>)||2485391|This warning indicates that the SAP HANA versions in a system replication environment don't match. During specific scenarios like NZDT upgrades using system replication this situation can exist for a certain time, but you should avoid operating inconsistent database versions in system replication environments for a longer time.|drGetServers|incompatible version from dc|but expected
sr_nameserver|DRRequestHandler.cpp|volume 2 successfully initialized for system replication||1999880|Volume registration for system replication|volume 2 successfully initialized for system replication||
sr_nameserver|TNSClient.cpp|error when sending request '<request>' to <secondary_host>:<port>: <error>||1999880|This error is written when the secondary system replication site is no longer reachable from primary site, e.g. because it is down or there is a network issue. <request> is the actual system replication request that failed, e.g. dr_getservers dr_changeinifileentries. <error> can be for example: connection refused OR internal error|error when sending request|to|
sr_nameserver|TNSClient.cpp|Remove following ini file entry on site '<site_id>': <file>.ini/<layer>//[<section>]/<parameter> =||1999880|These trace file entries are written when a SAP HANA parameter change is replicated to the secondary system replication site when the parameter replication feature is active: global.ini -> [inifile_checker] -> replicate = 'true'|Remove following ini file entry on site||
sr_nameserver|TNSClient.cpp|Remove following ini file entry on site '<site_id>': <file>.ini/<layer>//[<section>]/<parameter> =||1999880|These trace file entries are written when a SAP HANA parameter change is replicated to the secondary system replication site when the parameter replication feature is active: global.ini -> [inifile_checker] -> replicate = 'true'|Replicate following ini file entry to site||
sr_nameserver|TopologyUtil.cpp|error in topology - cannot prepare topology for system replication takeover; if this site was never started after -sr_register, you can use -sr_cleanup to clear system replication||1999880|This error indicates that the topology couldn't be prepared for system replication takeover purposes. It can be a consequence of the fact that the system replication site ID isn't defined in the following parameter: global.ini -> [system_replication] -> site_id|error in topology|cannot prepare topology for system replication takeover|
Statement|mvcc_anti_ager.cc|There are too many lock items on this system|T0708|1999998|High amount of transactional locks|There are too many lock items on this system||
Statement|mvcc_anti_ager.cc|long running cursor detected||2169283|Potential garbage collection blockers|long running cursor detected||
Statement|mvcc_anti_ager.cc|long running external transaction detected||2169283|Potential garbage collection blockers|long running external transaction detected||
Statement|mvcc_anti_ager.cc|long running uncommitted write transaction detected||2169283|Potential garbage collection blockers|long running uncommitted write transaction detected||
Statement|mvcc_anti_ager.cc|The Connection <conn_id> is disconnected forcefully because it is blocking garbage collection for too long period||2169283|Potential garbage collection blockers|The Connection|is disconnected forcefully because it is blocking garbage collection for too long period|
Statement|mvcc_anti_ager.cc|There are too many un-collected versions||2169283|Potential garbage collection blockers|There are too many un-collected versions||
Statement|mvcc_anti_ager.cc|The cursor blocks the garbage collection of the table <schema>.<table>||2169283|Potential garbage collection blockers|The cursor blocks the garbage collection of the table||
Statement|mvcc_anti_ager.cc|The transaction blocks the garbage collection of the table <schema>.<table>||2169283|Potential garbage collection blockers|The transaction blocks the garbage collection of the table||
StatementResourc|StatementResourceTracking.cc|statistics collection is not finished: stmt=<id>, stmtid=<id>|T0330|2222250|This error is linked to resource tracking and indicates that the resource tracking of the previous database request hasn't finished. It can be a consequence of the problem described in SAP Note 2706472 that is fixed with SAP HANA >= 1.00.122.22, >= 2.00.024.07 and >= 2.00.035. In other cases check for related errors in the trace file and open a SAP incident for assistance if required.|statistics collection is not finished|stmt|stmtid
StatementRouting|Connection.cc and sm_codec_newdb.cc|failed to join XA session due to active user transaction: joining ... (newdb codec, tx flags) session will be closed due to the error: [600] failed routed execution: failed to join XA session due to active user transaction|T0241|2691896|This error indicates a problem with an XA session during a distributzed query execution.|failed to join XA session due to active user transaction|joining|
StatementRouting|Connection.cc and sm_codec_newdb.cc|failed to join XA session due to active user transaction: joining ... (newdb codec, tx flags) session will be closed due to the error: [600] failed routed execution: failed to join XA session due to active user transaction|T0241|2691896|This error indicates a problem with an XA session during a distributzed query execution.|session will be closed due to the error|failed routed execution|failed to join XA session due to active user transaction
Statistics|qx_trex.cc|User reset monitor <monitoring_view>||2000000|Explicit reset of monitoring view: ALTER SYSTEM RESET MONITORING VIEW <monitoring_view>|User reset monitor||
Statistics|TaskStatisticsManager.cpp|Cleanup SQL query executed and found following task execution Id's: [<id>]||2169283|This information message is printed when data provisioning task monitor garbage collection takes place. The check interval is controlled by the parameter <service>.ini -> [task_framework] -> task_data_retention_period_check_interval.|Cleanup SQL query executed and found following task execution Id||
STATS_CTRL|NameServerControllerThread.cpp|making sure old StatisticsServer is inactive statisticsserver.ini: statisticsserver_general, active=false||2147247|Cleanup of standalone statistics server relics|making sure old StatisticsServer is inactive statisticsserver.ini|statisticsserver_general|
STATS_CTRL|NameServerControllerThread.cpp|no old StatisticsServer in topology||2147247|Cleanup of standalone statistics server relics|no old StatisticsServer in topology||
STATS_CTRL|NameServerControllerThread.cpp|removing old section from statisticsserver.ini: statisticsserver_general||2147247|Cleanup of standalone statistics server relics|removing old section from statisticsserver.ini|statisticsserver_general|
table_consistenc|ColumnStoreConsistencyChecker.cc|ColumnStoreConsistencyChecker found errors for table <table>: <inconsistencies>|T0440|2116157|This error message indicates that an inconsistency was found when checking a table with CHECK_TABLE_CONSISTENCY.|ColumnStoreConsistencyChecker found errors for table||
TableLock|ObjectLockManagerImpl.cpp|Failed to get table location during table lock, TRANSACTION_ID=<tid> , UPDATE_TRANSACTION_ID=<utid> , Database name= , Schema name=<schema> , Table name=<table_name>, error=table does not exist|T0708|1999998|This error indicates that locking a table isn't possible because it wasn't found. This can e.g. happen when the table is dropped (e.g. because it is a temporary table) and a lock is requested at the same time by another transaction.|Failed to get table location during table lock|TRANSACTION_ID|UPDATE_TRANSACTION_ID
TableReload|TRexApiSystem.cpp|Failed to reload table <table>: UNKNOWN_ATTRIBUTE (AttributeEngine);index=<table>Sen,attribute=<column>||2669634|This error indicates a problem during table reload (SAP Note 2127458).|Failed to reload table|UNKNOWN_ATTRIBUTE|
TableReload|TRexApiSystem.cpp|Starting reloading column store tables based on previous load information||2222217|Load of column store tables into memory after SAP HANA startup|Starting reloading column store tables based on previous load information||
TableReload|TRexApiSystem.cpp|Now reloading <total> tables (loading up to <num> tables in parallel)||2222217|Load of column store tables into memory after SAP HANA startup|Now reloading|loading up to|tables in parallel
TableReload|TRexApiSystem.cpp|Finished table reloading||2222217|Load of column store tables into memory after SAP HANA startup|||
table_update|TableUpdate.cpp|TableUpdate internal error: Inconsistent lateMat pageSizes <size1>, <size2>|T0855|1975448|Inconsistency during late materialization|TableUpdate internal error|Inconsistent lateMat pageSizes|
table_update|TableUpdateTrace.cpp|executed statement: <sql_statement>, user: <user>, called from execute_local aborted||2092196|Termination of a database request (e.g. manually or due to a timeout setting)|executed statement|user|called from execute_local aborted
tempindex|trex_itab.cc|Failed to find temp table. Schema: <schema>, Name: <temp_index>, Host: <host>, Port: <port>|T0241||This error indicates that a temporary table / temp index can't be found (e.g. during procedure execution).|Failed to find temp table|Schema|Host
Thread|Context.cpp|SharedLock overflow on context: <context>||1999998|This message is printed when storing shared lock information in the thread context isn't possible due to an overflow. It is harmless and doesn't result in terminations of database requests. It can only impact deadlock detection on internal locks. With more recent SAP HANA Revisions this trace entry is no longer generated. This message is often related to statistics server procedures related to liveCache histories (SAP Note 2000002): COLLECTOR_LIVECACHE_CONTAINER_STATISTICS (statement hash 2d40db6145e579aa5c23e42337750ee8) OR COLLECTOR_LIVECACHE_SCHEMA_STATISTICS (statement hash 5157ba1bc92d3166d7eab858566f9ea1)|SharedLock overflow on context||
Threads|Thread.cpp|<thread_type> thread creation error: 11 (Resource temporarily unavailable)|T0318|2600030|On SLES >= 12.2 this error can be a consequence of not having set UserTasksMax=infinity in /etc/systemd/logind.conf.d/sap.conf. It can also be a consequence of a low setting of nproc on OS level that prevents the creation of additional processes / threads.|thread creation error|Resource temporarily unavailable|
TNS|TNSInfo.cpp|<service> <host>:<port> not responding. retry in 5 sec...|T0562|2222200|No response from a SAP HANA service|not responding|retry in 5 sec|
topology|Topology.cpp|assign failed with persistence startup error. ERROR [SQL-3] fatal error: A downward catalog migration from <source> to <target> is not supported||2668556|This error is issued during startup when you try to start SAP HANA with a catalog version lower than the actually existing version. This can happen when you follow unsupported upgrade paths or try to run an existing SAP HANA database with an earlier Revision level.|assign failed with persistence startup error|ERROR|A downward catalog migration from
TraceContext|TraceContext.cpp|UserName=<db_user> ApplicationUserName=<app_user> ApplicationName=<app_name> ApplicationSource=<app_source> Client=<client>|||Context information for preceeding / subsequent trace file lines|UserName|ApplicationUserName|ApplicationName
Transaction|transdtx.cc|invalidate_external_inuse_count is not finished in <ms> ms|T0867|2092196|This error indicates that invalidating external transaction references didn't finish in time. In the worst case it got completely stuck and can't be cancelled. Follow-up problems like garbage collection issues or lock contention are possible. SAP Note 2092196 describes known stuck scenarios ("ptime::Transaction::invalidate_external_inuse_count").|invalidate_external_inuse_count is not finished in|ms|
TrexNet|BufferedIO.cpp|erroneous channel (since <us>mues) <channel> from <source_host>:<source_port> to <target_port> with method <method> with id <id> on host <target_host> on port <target_port> from process <proces> with service port <port>, pid <pid> and tid <tid> from parent host <host> and parent process <process> with parent service port <port>, parent pid <pid> and parent tid <tid>: trying to read from erroneous channel ... erroneous channel <channel> from <source_host> to <target_host>:<target_port>: read from channel failed; resetting buffer||2222200|These errors indicate problems in the network / communication area.|trying to read from erroneous channel||
TrexNet|Communication.cpp|details: Internal Error. getaddrinfo failed with error -2||2222200|These errors indicate a problem during name resolution, e.g. a wrong configuration in sections [system_replication_hostname_resolution]  or [internal_hostname_resolution].|Internal Error|getaddrinfo failed with error|
TrexNet|Communication.cpp|details: Internal Error. getaddrinfo failed with error -2||2222200|These errors indicate a problem during name resolution, e.g. a wrong configuration in sections [system_replication_hostname_resolution]  or [internal_hostname_resolution].|failed to resolve vhkfrpczdb03|internal error|
trex_qo|Evaluate.cpp|searchDocuments failed; rc: 6931 (attribute value is not a date or wrong syntax);|T0235|2361364 2581766|This error indicates a problem when parsing a data value.|searchDocuments failed|6931|attribute value is not a date or wrong syntax
TrexTrace|TrexTrace.cpp|no sql_user defined in inifile section [traceprofile_<user>]||2119087|This error is reported if no database user is maintained for a particular user-specific trace. It can be ignored because a user-specific trace works fine even if no sql_user is specified (but instead e.g. only an application_user).|no|defined in inifile section|
u_trigger|TriggerExecutor.cpp|Failed to execute trigger '<schema>:<trigger>' (triggered by update on table <schema>:<table>)|T0860||Error during execution of a SAP HANA trigger|Failed to execute trigger|triggered by update on table|
tu_trigger|TriggerExecutor.cpp|Llang Runtime Error: FatalException::ExecutionCanceled ...: [132] ExecutionCanceled exception||2092196|Cancellation during trigger processing|Llang Runtime Error|FatalException|ExecutionCanceled exception
tz|DateParser.cpp|Time zone validity checker could not find database tables with timezone data. Aborting validity check. Please make sure that you have up-to-date timezone data tables. (see SAP Note 1932132)|T0865|1932132|This trace entry indicates that no dedicated SAP HANA database tables with timezone information (like TTZZ) were found. It is not necessarily an issue to work with default timezones rather than with imported timezone tables. As a best practice you should nevertheless make sure that the timezone data tables are properly imported and configured (SAP Note 1932132).|Time zone validity checker could not find database tables with timezone data|Aborting validity check|
tz|IANATimezones.cpp|Error timezone string <timezone>.|T0866|1932132|These messages indicate that the value found in operating system environment variable TZ of the SAP HANA user (e.g. <sid>adm) doesn t follow the POSIX notation and so a fallback to UTC (i.e. UTC0) is done.|Error timezone string||
tz|IANATimezones.cpp|Falling back to using UTC as local timezone (timezone string UTC0)|T0866|1932132|These messages indicate that the value found in operating system environment variable TZ of the SAP HANA user (e.g. <sid>adm) doesn t follow the POSIX notation and so a fallback to UTC (i.e. UTC0) is done.|Falling back to using UTC as local timezone||
tz|IANATimezones.cpp|Unexpected end encountered when parsing POSIX timezone string: <timezone>|T0866|1932132|These messages indicate that the value found in operating system environment variable TZ of the SAP HANA user (e.g. <sid>adm) doesn t follow the POSIX notation and so a fallback to UTC (i.e. UTC0) is done.|Unexpected end encountered when parsing POSIX timezone string||
warm_upper|WarmUpper.cp|::writeTablePreloadInfo enter ... <num_tables> tables are open ... ::writeTablePreloadInfo exit||2127458|These messages are written in context of column preload that is controlled with the following SAP HANA parameter: global.ini -> [system_replication] -> preload_column_tables|writeTablePreloadInfo||
xsa:APPL.MAPL.CP|SandBox.cpp|Found the following errors: ... TypeError: $.request.body is undefined||2169923|This error indicates an error in a script definition or problems with metadata interpretation.|Found the following errors|TypeError|request.body is undefined
xsa:sap.hana.xs.|SandBox.cpp|The execution of the script has exceeded the maximum request runtime.|T1700|2000003|This termination can happen when an XS transaction runs for more than the number of seconds defined with the following SAP HANA parameter (default: 300 s): xsengine.ini -> [httpserver] -> max_request_runtime|The execution of the script has exceeded the maximum request runtime||
XSRequestHandler|RequestHandler.cpp|Can't serialize response <id>|||This error is possible in case of an overload or error situation related to the XS engine (e.g. terminations with This is typically a consequence of other errors, e.g. terminations with "The execution of the script has exceeded the maximum request runtime").|Can|t serialize response|
XSSession|XSSessionLifecycle.cpp|Assertion authentication for user failed with reason: Assertion is no longer valid(StatusCode: , StatusMessage: )|T0920|2528123|This error can be reported in context XS engine authentication. Further traces can be activated to understand and resolve the security issue.|Assertion authentication for user failed with reason|Assertion is no longer valid|
